{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T22:59:09.832326Z",
     "start_time": "2024-12-02T22:59:08.692576Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (2.13.0)\n",
      "Requirement already satisfied: numpy in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (1.24.3)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (89 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.3-cp39-cp39-macosx_10_12_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_12_0_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (2.5.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (164 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.0.0-cp39-cp39-macosx_10_10_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.36.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Using cached pandas-2.2.3-cp39-cp39-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "Downloading matplotlib-3.9.3-cp39-cp39-macosx_10_12_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading scikit_learn-1.5.2-cp39-cp39-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached opencv_python-4.10.0.84-cp37-abi3-macosx_12_0_x86_64.whl (56.5 MB)\n",
      "Downloading contourpy-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl (265 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.0-cp39-cp39-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.7-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "Using cached pillow-11.0.0-cp39-cp39-macosx_10_10_x86_64.whl (3.2 MB)\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-macosx_10_9_x86_64.whl (39.4 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, typing-extensions, threadpoolctl, scipy, pyparsing, pillow, opencv-python, kiwisolver, joblib, importlib-resources, fonttools, cycler, contourpy, scikit-learn, pandas, matplotlib, seaborn\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.55.0 importlib-resources-6.4.5 joblib-1.4.2 kiwisolver-1.4.7 matplotlib-3.9.3 opencv-python-4.10.0.84 pandas-2.2.3 pillow-11.0.0 pyparsing-3.2.0 pytz-2024.2 scikit-learn-1.5.2 scipy-1.13.1 seaborn-0.13.2 threadpoolctl-3.5.0 typing-extensions-4.5.0 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy pandas matplotlib seaborn scikit-learn opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34f36314d38d776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:01:06.634981Z",
     "start_time": "2024-12-02T23:00:38.531805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.13.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (4.25.5)\n",
      "Requirement already satisfied: setuptools in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorflow==2.13.0) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.36.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.21.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/calebmusfeldt/opt/anaconda3/envs/emodet/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf15cb2530f6fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:02:23.776450Z",
     "start_time": "2024-12-02T23:02:04.417339Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "model.summary()  # Displays the model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff4cd22c091b8df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T20:50:25.863185Z",
     "start_time": "2024-12-02T20:50:25.786607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv2d_16\n",
      "Weights: [array([[[[ 0.10905346, -0.00711864,  0.02804574, -0.07914691,\n",
      "           0.10268161, -0.02861219,  0.07640784, -0.08791925,\n",
      "           0.02755754,  0.14736876,  0.11956773, -0.06543504,\n",
      "          -0.05550323,  0.11026922, -0.05081695,  0.01007335,\n",
      "           0.07090794, -0.12507734, -0.05949271, -0.1196112 ,\n",
      "           0.14763689, -0.09371238, -0.02478594,  0.005924  ,\n",
      "           0.00793075, -0.15240411, -0.03761547,  0.12204679,\n",
      "          -0.01981928, -0.15644297, -0.03349183, -0.02629297,\n",
      "          -0.03214603, -0.00137614, -0.06914955, -0.00714613,\n",
      "          -0.08062661, -0.01758199, -0.01201051, -0.10659512,\n",
      "          -0.03300463, -0.05357308,  0.1509959 , -0.11682671,\n",
      "          -0.05801814, -0.08545687, -0.04191796,  0.04815565,\n",
      "          -0.19722395, -0.02044796, -0.04276922,  0.02772859,\n",
      "          -0.05818393, -0.05181078, -0.21784523,  0.10477517,\n",
      "           0.142115  , -0.08459506, -0.00684312, -0.05279872,\n",
      "          -0.00312971, -0.0539901 ,  0.12110028,  0.07945061]],\n",
      "\n",
      "        [[ 0.03813662, -0.10556363,  0.00947642, -0.03487339,\n",
      "           0.08110206,  0.00831989, -0.11188531,  0.04317856,\n",
      "          -0.04230702,  0.09051757,  0.09713731, -0.1421398 ,\n",
      "           0.05789119,  0.13463755, -0.10444342, -0.05687892,\n",
      "           0.10369161, -0.08739873,  0.08698059,  0.0373292 ,\n",
      "          -0.07907283, -0.03939935,  0.05812498,  0.04129616,\n",
      "           0.00808983, -0.04013355, -0.09443188,  0.14351673,\n",
      "          -0.06260208, -0.12516811,  0.06598637,  0.08244593,\n",
      "           0.02518451, -0.02265443,  0.04613849, -0.10776668,\n",
      "           0.02935048, -0.06652848,  0.0296885 , -0.13854338,\n",
      "          -0.0396281 ,  0.04282452,  0.01723377,  0.06208257,\n",
      "          -0.06749266,  0.14459328, -0.11081322, -0.02517148,\n",
      "          -0.14262581, -0.01548659, -0.11780903, -0.07524583,\n",
      "           0.0838569 , -0.06917477, -0.11968489,  0.06547958,\n",
      "          -0.11369814, -0.04666836,  0.11962421,  0.07974087,\n",
      "          -0.12673421, -0.07283083, -0.08677323, -0.0797499 ]],\n",
      "\n",
      "        [[-0.04163709, -0.14671297, -0.06985197,  0.02641458,\n",
      "          -0.14434177,  0.125948  , -0.03554312,  0.01037136,\n",
      "          -0.00080434,  0.04391887,  0.11428967, -0.01331842,\n",
      "           0.0402303 ,  0.05081563, -0.12070702,  0.02453911,\n",
      "          -0.04486783,  0.09668856, -0.07452797, -0.02631482,\n",
      "          -0.19570568,  0.05513419, -0.04995009,  0.02807872,\n",
      "          -0.11923877, -0.13566135,  0.12181722,  0.04422164,\n",
      "           0.0053309 ,  0.01915144,  0.07845099,  0.08647181,\n",
      "          -0.01034501, -0.09932466, -0.09500927, -0.07522367,\n",
      "           0.04038475, -0.02959785,  0.12390812,  0.00334198,\n",
      "          -0.08812753,  0.0293331 ,  0.03583486,  0.08997655,\n",
      "          -0.11926132, -0.04984613,  0.16177766, -0.0342573 ,\n",
      "           0.04122435, -0.04286018, -0.04020503,  0.00242172,\n",
      "          -0.04759379,  0.12185954,  0.12816921, -0.02548909,\n",
      "           0.01770912, -0.05688074, -0.07177187,  0.14160784,\n",
      "           0.10418802, -0.09610558, -0.06088946, -0.07624334]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00772222, -0.08131932, -0.12112783, -0.05076505,\n",
      "           0.07274494,  0.00670166,  0.04858626, -0.03959785,\n",
      "          -0.12296804, -0.08997496, -0.06275468, -0.12074797,\n",
      "           0.11111347, -0.10693665, -0.0844294 , -0.17418267,\n",
      "          -0.03454842, -0.11290453, -0.06896874, -0.11169049,\n",
      "           0.01887653,  0.02559977,  0.0239455 , -0.13734749,\n",
      "          -0.01856065, -0.07834259, -0.14528656, -0.13227844,\n",
      "          -0.04676106,  0.09006251,  0.12733445, -0.15213424,\n",
      "          -0.02618275, -0.04729145, -0.06682932, -0.03455971,\n",
      "          -0.07830768,  0.03760652, -0.10568642,  0.087007  ,\n",
      "          -0.1067151 , -0.12054532,  0.04007765,  0.01036007,\n",
      "           0.08308063, -0.09675833, -0.06795844,  0.10320813,\n",
      "          -0.08654754, -0.09124469,  0.0103158 , -0.02254059,\n",
      "           0.0439654 , -0.15344766, -0.05888925,  0.1053921 ,\n",
      "           0.10041406, -0.13020942,  0.063145  , -0.03102691,\n",
      "          -0.03656968, -0.08672075,  0.06577159, -0.1027112 ]],\n",
      "\n",
      "        [[ 0.08706836,  0.03311143, -0.06148822, -0.13961707,\n",
      "           0.05912124,  0.03026195, -0.1654767 , -0.09391647,\n",
      "          -0.06811732, -0.00580567, -0.13597448, -0.01020651,\n",
      "           0.01311491,  0.01537878, -0.08212361, -0.0693349 ,\n",
      "          -0.01805548,  0.12140365,  0.00404045,  0.04293677,\n",
      "          -0.08013366, -0.07932489,  0.01613069, -0.16147004,\n",
      "           0.08246505, -0.20993118,  0.03311613, -0.13186133,\n",
      "          -0.12707719,  0.01789579,  0.07285111, -0.15305385,\n",
      "          -0.05561523,  0.03970007,  0.04340726,  0.0659789 ,\n",
      "          -0.08258155, -0.03234012, -0.02146505,  0.04537054,\n",
      "           0.02672853, -0.0823639 , -0.12191547, -0.09865526,\n",
      "           0.12213252, -0.02905213, -0.03943645,  0.02161779,\n",
      "           0.01487988, -0.08426789, -0.03524122, -0.01093525,\n",
      "          -0.00759788,  0.05152714,  0.05644991, -0.08293946,\n",
      "          -0.14387791,  0.10900328,  0.05421515, -0.01387474,\n",
      "          -0.00801711, -0.03908415, -0.08689918, -0.09607087]],\n",
      "\n",
      "        [[ 0.05464245,  0.04680955,  0.03475254,  0.07385881,\n",
      "          -0.12920389, -0.0196649 ,  0.00271196, -0.02155385,\n",
      "          -0.04935239, -0.09028427, -0.15494339,  0.02041539,\n",
      "          -0.07179896, -0.09154498,  0.03520758, -0.03339496,\n",
      "          -0.0595367 , -0.02115611,  0.04960382,  0.01463686,\n",
      "          -0.02508765, -0.19313745,  0.00222444, -0.05836047,\n",
      "          -0.01941227, -0.09556475,  0.11981529, -0.02984431,\n",
      "          -0.02983427, -0.0547104 , -0.10295638,  0.08487824,\n",
      "          -0.00798971, -0.0041079 , -0.08726723, -0.10453478,\n",
      "           0.04710683,  0.02404773,  0.07210204, -0.11654744,\n",
      "           0.05080849, -0.0106669 , -0.1558325 ,  0.01342321,\n",
      "           0.01554635, -0.02816042,  0.07665323, -0.14185274,\n",
      "          -0.06784886,  0.02879943,  0.00242581, -0.04853675,\n",
      "           0.00706391,  0.1130525 , -0.02252234, -0.10730566,\n",
      "          -0.11450885,  0.08292386,  0.06758337,  0.01148053,\n",
      "          -0.10140477, -0.04504795, -0.04304029, -0.09173808]]],\n",
      "\n",
      "\n",
      "       [[[-0.1537558 ,  0.07118357,  0.03858057,  0.18213868,\n",
      "           0.0672461 ,  0.03510484,  0.0734949 , -0.03347421,\n",
      "          -0.02100486, -0.01092145, -0.07927535,  0.0900958 ,\n",
      "           0.11531493, -0.1061856 , -0.06115732, -0.03814561,\n",
      "          -0.07528216,  0.05078731, -0.09113146, -0.15412478,\n",
      "          -0.06900536,  0.05739562, -0.05384408,  0.03201243,\n",
      "           0.02163917,  0.05823431, -0.11201473,  0.06116802,\n",
      "           0.03241702,  0.14369352,  0.0625453 , -0.08020046,\n",
      "           0.02906317,  0.00364844, -0.03812878,  0.11478903,\n",
      "          -0.03827861, -0.11648457,  0.00249483, -0.05210643,\n",
      "          -0.04187327, -0.07019181, -0.05032297, -0.02345824,\n",
      "           0.06625396, -0.072677  , -0.01220516, -0.03405551,\n",
      "           0.07825438, -0.00889635,  0.01146886,  0.01766477,\n",
      "          -0.04924479, -0.01355281,  0.11675204, -0.0950017 ,\n",
      "          -0.01064702, -0.05612286, -0.11004893, -0.07569905,\n",
      "           0.06568149,  0.01909693,  0.14512216, -0.08417787]],\n",
      "\n",
      "        [[-0.03162554, -0.08946689, -0.08081692, -0.04958013,\n",
      "           0.07285381, -0.05134758, -0.10186547,  0.00805587,\n",
      "           0.01683086,  0.0054253 ,  0.01941229,  0.05797976,\n",
      "          -0.00123515, -0.11017089, -0.04998371, -0.0906131 ,\n",
      "          -0.09854036,  0.07773059, -0.00541993,  0.05501628,\n",
      "          -0.09650601,  0.06962696, -0.05948444,  0.12017151,\n",
      "           0.05538778,  0.01039816,  0.00443187,  0.01645418,\n",
      "          -0.12489833, -0.0410791 , -0.05458866,  0.05710678,\n",
      "          -0.05314378, -0.02677749, -0.0921702 ,  0.00199702,\n",
      "          -0.04175971, -0.07110527, -0.09310231, -0.00891302,\n",
      "          -0.02851534, -0.00666456, -0.07770981,  0.00630449,\n",
      "           0.02360972,  0.05988702, -0.01588698, -0.06260548,\n",
      "           0.09316045, -0.05611238, -0.14499155, -0.05543409,\n",
      "           0.00512916,  0.08603836,  0.00331144, -0.10698766,\n",
      "          -0.14008972,  0.09588004, -0.16122748, -0.10749277,\n",
      "          -0.11559922,  0.07884366, -0.02360611, -0.06428225]],\n",
      "\n",
      "        [[-0.02367899,  0.03949925, -0.02900249, -0.08161992,\n",
      "          -0.08609251, -0.02548476,  0.06837036,  0.00385119,\n",
      "           0.02250868, -0.03787358,  0.08401231,  0.16352567,\n",
      "          -0.15222004,  0.08546346,  0.02768442,  0.02155761,\n",
      "          -0.05918062, -0.00474645,  0.04052413, -0.00433682,\n",
      "           0.01707437,  0.06479397, -0.0634561 ,  0.10600904,\n",
      "           0.05848173, -0.11178685,  0.06519202, -0.04054155,\n",
      "          -0.00914461,  0.11162328, -0.05750466, -0.09340736,\n",
      "           0.05071022,  0.01722282, -0.08699089,  0.1501105 ,\n",
      "          -0.05787017,  0.10422585,  0.080984  ,  0.05310449,\n",
      "          -0.13126917,  0.02883252,  0.10851742, -0.12605162,\n",
      "           0.0356325 ,  0.01514877,  0.02473906, -0.02972022,\n",
      "          -0.03055299,  0.00839073,  0.08379018,  0.03332392,\n",
      "          -0.0466974 , -0.06171664, -0.07551506, -0.12036502,\n",
      "          -0.06684592,  0.04929848,  0.01965078,  0.11446409,\n",
      "           0.0823236 , -0.08600485, -0.01336536,  0.00318883]]]],\n",
      "      dtype=float32), array([ 0.06433871, -0.02853372, -0.00498531,  0.03468791,  0.06460024,\n",
      "        0.08650506,  0.02019369, -0.0099513 , -0.01168178,  0.04305689,\n",
      "        0.00741786,  0.03331618,  0.01607916,  0.04571842, -0.01472044,\n",
      "        0.0237362 , -0.02449755,  0.06921359,  0.01275542, -0.03184449,\n",
      "       -0.00840793, -0.00143572, -0.03316758,  0.04674461,  0.03939087,\n",
      "       -0.0060645 ,  0.05258181,  0.06006452, -0.01129843,  0.05170262,\n",
      "        0.04582618,  0.01949901, -0.03908051, -0.01267106, -0.00777679,\n",
      "        0.08120259, -0.0059808 , -0.00207243,  0.02368781, -0.02612401,\n",
      "       -0.00201528, -0.0252381 ,  0.00516963, -0.00499664,  0.04258622,\n",
      "       -0.0180166 ,  0.04236744, -0.00890727,  0.03049699, -0.01263642,\n",
      "        0.03366832, -0.04345113,  0.07222819,  0.08808438, -0.0091915 ,\n",
      "       -0.01487087,  0.00341032,  0.06781813,  0.05372541,  0.03038037,\n",
      "        0.01950731, -0.0047075 ,  0.06624891, -0.02422757], dtype=float32)]\n",
      "\n",
      "Layer: batch_normalization_20\n",
      "Weights: [array([0.9522672 , 1.0266908 , 0.97756106, 1.0263528 , 1.1209973 ,\n",
      "       0.6988955 , 0.96747166, 0.9701978 , 1.0036994 , 0.85284615,\n",
      "       1.1776664 , 1.1211517 , 1.0774319 , 1.1192498 , 1.0018321 ,\n",
      "       0.9524967 , 0.98799807, 1.1774622 , 0.8386003 , 0.9249673 ,\n",
      "       1.0864531 , 0.99979985, 0.9855659 , 1.0811689 , 0.8253569 ,\n",
      "       0.97130555, 1.1576996 , 1.103326  , 0.9342734 , 1.152338  ,\n",
      "       0.9008234 , 1.0220063 , 0.9426695 , 0.9320472 , 0.99522394,\n",
      "       1.1150739 , 0.9853485 , 1.0271661 , 0.9457543 , 0.986958  ,\n",
      "       0.9082675 , 1.0179055 , 1.1986171 , 0.9800151 , 0.98055345,\n",
      "       0.8219495 , 1.0775621 , 0.96674085, 1.1083096 , 0.9273707 ,\n",
      "       0.9238554 , 0.9582078 , 0.8201942 , 1.1157297 , 1.0805429 ,\n",
      "       1.0447688 , 1.0518496 , 1.0372022 , 1.0368547 , 0.77710366,\n",
      "       1.0145897 , 0.99800414, 1.1276805 , 0.9919214 ], dtype=float32), array([-0.12003443,  0.03320516,  0.00400208,  0.06044081, -0.03115742,\n",
      "       -0.11803187,  0.01186214,  0.0285106 , -0.03027636,  0.05319583,\n",
      "       -0.14704219, -0.03082771, -0.07877324, -0.0920726 , -0.01906672,\n",
      "       -0.03960397, -0.04847095, -0.07216679,  0.0558827 ,  0.03910234,\n",
      "        0.00660098,  0.02425437, -0.04117996, -0.00535689, -0.07124275,\n",
      "        0.07159447, -0.00727655, -0.02304206, -0.02059576, -0.12426659,\n",
      "       -0.02255353,  0.01383499, -0.05226612,  0.00759985, -0.01392454,\n",
      "       -0.02375928,  0.05505138,  0.01533663,  0.03966457,  0.02495121,\n",
      "       -0.0056294 , -0.00554969, -0.14333786, -0.00882805,  0.02338949,\n",
      "        0.01431588, -0.02072565, -0.05977226, -0.03688866,  0.02634024,\n",
      "        0.01426776,  0.00906477,  0.00433376, -0.03225515,  0.02264091,\n",
      "       -0.00178317, -0.01031275, -0.01198315, -0.03569004, -0.0205873 ,\n",
      "       -0.00246441,  0.07498885, -0.07877698, -0.01386771], dtype=float32), array([9.5126361e-02, 5.3252625e-06, 4.6968853e-07, 4.0320661e-03,\n",
      "       9.8466210e-02, 1.3382980e-01, 1.5778452e-02, 4.3723691e-07,\n",
      "       1.2341168e-07, 7.6413833e-02, 2.6481755e-02, 3.2805834e-02,\n",
      "       4.6941444e-02, 4.7904566e-02, 1.2227136e-07, 4.9416634e-04,\n",
      "       9.1253256e-05, 6.1113324e-02, 9.4558569e-03, 6.0387264e-04,\n",
      "       3.1227243e-04, 3.2635729e-04, 7.7357899e-06, 2.8790910e-02,\n",
      "       7.3868193e-02, 5.6530484e-07, 4.4971868e-02, 5.8417965e-02,\n",
      "       6.2585714e-09, 6.5210871e-02, 1.2750024e-01, 4.5448723e-03,\n",
      "       3.6750001e-09, 2.8566296e-06, 4.7760591e-07, 8.3609462e-02,\n",
      "       6.8029440e-05, 1.8700838e-04, 4.8253801e-02, 1.0462659e-05,\n",
      "       2.8834981e-07, 2.3258938e-06, 1.7792411e-02, 9.7770986e-05,\n",
      "       7.8382343e-02, 7.1113423e-04, 3.8281798e-02, 8.0159819e-04,\n",
      "       2.6392578e-03, 1.2550558e-08, 2.4128677e-03, 6.3063266e-18,\n",
      "       5.6762788e-02, 8.6959094e-02, 1.6654759e-04, 1.3614558e-03,\n",
      "       6.2138337e-04, 5.4615688e-02, 4.8162568e-02, 7.8100622e-02,\n",
      "       7.0200081e-04, 2.5526151e-06, 7.1161062e-02, 1.1795318e-07],\n",
      "      dtype=float32), array([1.01614476e-03, 1.10120098e-07, 3.50124996e-09, 1.14897302e-04,\n",
      "       2.64278427e-03, 7.73298787e-04, 2.51073594e-04, 4.26518598e-09,\n",
      "       8.63857430e-10, 1.29959336e-03, 4.18665353e-04, 1.11613097e-03,\n",
      "       9.89379245e-04, 8.90020980e-04, 1.40815060e-09, 8.52673747e-06,\n",
      "       3.41053851e-06, 9.36289725e-04, 2.43976756e-04, 3.64785701e-05,\n",
      "       1.12724974e-05, 1.03831017e-05, 1.67039829e-07, 4.60410025e-04,\n",
      "       8.41488538e-04, 7.52782991e-09, 1.54777884e-03, 5.50486264e-04,\n",
      "       2.70360036e-11, 1.23010250e-03, 2.25633848e-03, 2.15944019e-04,\n",
      "       3.29667856e-11, 3.67556403e-08, 8.51798365e-09, 1.03152904e-03,\n",
      "       1.45257138e-06, 4.71435396e-06, 9.10724106e-04, 2.92537493e-07,\n",
      "       4.25851354e-09, 3.30489272e-08, 3.22679378e-04, 3.24517873e-06,\n",
      "       1.45979668e-03, 4.42316887e-05, 6.27978006e-04, 3.22418273e-05,\n",
      "       8.87583010e-05, 1.02376996e-10, 6.54364630e-05, 4.64053494e-19,\n",
      "       2.40717040e-04, 1.14265573e-03, 5.68166115e-06, 7.38608869e-05,\n",
      "       2.97606366e-05, 1.38471415e-03, 7.95177533e-04, 1.77859503e-03,\n",
      "       1.10261362e-05, 4.26819291e-08, 1.04333146e-03, 1.30929112e-09],\n",
      "      dtype=float32)]\n",
      "\n",
      "Layer: max_pooling2d_8\n",
      "Weights: []\n",
      "\n",
      "Layer: dropout_12\n",
      "Weights: []\n",
      "\n",
      "Layer: conv2d_17\n",
      "Weights: [array([[[[ 0.05796726, -0.12194432,  0.09388822, ...,  0.04449181,\n",
      "           0.02140155, -0.0722573 ],\n",
      "         [-0.07096368, -0.05343796, -0.07665595, ...,  0.03655673,\n",
      "          -0.06620622,  0.01638952],\n",
      "         [-0.03756829,  0.00450805,  0.03709184, ..., -0.04512706,\n",
      "          -0.02583145,  0.10122463],\n",
      "         ...,\n",
      "         [-0.05444464,  0.0833674 ,  0.02763238, ...,  0.04916419,\n",
      "           0.01715253, -0.00937448],\n",
      "         [-0.02801486, -0.05214674,  0.032184  , ...,  0.02498584,\n",
      "          -0.03279105,  0.08552765],\n",
      "         [-0.05579646, -0.03167312, -0.01788318, ..., -0.01844122,\n",
      "           0.00889811,  0.08204915]],\n",
      "\n",
      "        [[ 0.06131858, -0.03388936,  0.0115893 , ...,  0.05387628,\n",
      "           0.08321677,  0.01827444],\n",
      "         [-0.04283528, -0.02186369, -0.05743596, ...,  0.1014293 ,\n",
      "          -0.01817503, -0.00095249],\n",
      "         [-0.02746634,  0.01534065,  0.09252536, ..., -0.06310707,\n",
      "          -0.04208632,  0.04532866],\n",
      "         ...,\n",
      "         [ 0.03823681, -0.07077763, -0.03868107, ...,  0.07780645,\n",
      "          -0.02167988, -0.04919812],\n",
      "         [ 0.04043199, -0.04871774, -0.04252397, ..., -0.06496317,\n",
      "           0.03889818, -0.06009673],\n",
      "         [ 0.02266953, -0.00415522,  0.0414068 , ...,  0.00117658,\n",
      "           0.05417676, -0.02225932]],\n",
      "\n",
      "        [[-0.05460747, -0.04697749, -0.00970532, ..., -0.04156806,\n",
      "           0.04140188, -0.03059335],\n",
      "         [ 0.0292075 , -0.04267607, -0.07359542, ...,  0.02763744,\n",
      "          -0.0170962 , -0.08502001],\n",
      "         [ 0.01864638, -0.00771748,  0.00721731, ..., -0.07206274,\n",
      "           0.0196195 ,  0.08515181],\n",
      "         ...,\n",
      "         [ 0.0896809 , -0.00914685, -0.09689125, ...,  0.04543686,\n",
      "          -0.11152375,  0.13906974],\n",
      "         [ 0.06380989, -0.01398882, -0.10301634, ..., -0.02616766,\n",
      "          -0.04937899,  0.11852324],\n",
      "         [-0.07646156, -0.00940191, -0.01327153, ..., -0.06954013,\n",
      "           0.03703124,  0.08705668]]],\n",
      "\n",
      "\n",
      "       [[[-0.0430339 , -0.08093189, -0.13626002, ...,  0.05138354,\n",
      "           0.05794473, -0.03235535],\n",
      "         [-0.00658429, -0.06862485,  0.03282229, ...,  0.03378649,\n",
      "          -0.0712783 , -0.07055713],\n",
      "         [ 0.00631019,  0.02648318,  0.00897495, ..., -0.02177645,\n",
      "           0.154303  , -0.00300462],\n",
      "         ...,\n",
      "         [ 0.01633671,  0.02847091, -0.00025057, ..., -0.04045061,\n",
      "           0.0418391 ,  0.09011939],\n",
      "         [ 0.11322475, -0.03687945,  0.03862142, ..., -0.02098795,\n",
      "           0.01480805,  0.08459575],\n",
      "         [ 0.00217579,  0.02070181,  0.0534084 , ..., -0.02539898,\n",
      "          -0.01243857,  0.09227246]],\n",
      "\n",
      "        [[-0.04429235, -0.12457423, -0.11412338, ...,  0.03384147,\n",
      "           0.06373466, -0.00983723],\n",
      "         [-0.00164583,  0.01477272,  0.03730622, ...,  0.04078034,\n",
      "          -0.08099731, -0.09742088],\n",
      "         [-0.00713089,  0.01580041,  0.03183062, ..., -0.04005971,\n",
      "           0.00061898,  0.04133915],\n",
      "         ...,\n",
      "         [ 0.02132316, -0.02739982,  0.02527903, ..., -0.13438326,\n",
      "           0.00792927,  0.00863492],\n",
      "         [ 0.09395725, -0.03662753, -0.12454955, ...,  0.06255277,\n",
      "          -0.0377722 , -0.02455122],\n",
      "         [ 0.03030409, -0.03998721, -0.03301949, ..., -0.02540495,\n",
      "           0.03008325, -0.00966026]],\n",
      "\n",
      "        [[-0.05719266, -0.04639116,  0.02236614, ..., -0.03866993,\n",
      "           0.02173986,  0.04136738],\n",
      "         [ 0.03429918, -0.04934115, -0.06047622, ..., -0.04490932,\n",
      "          -0.07268019, -0.07580151],\n",
      "         [ 0.03840896, -0.06992129,  0.06219578, ...,  0.01751899,\n",
      "           0.05875045,  0.05642156],\n",
      "         ...,\n",
      "         [ 0.06181834,  0.01002957, -0.12780806, ...,  0.02492288,\n",
      "          -0.09856106,  0.12915868],\n",
      "         [ 0.07059705, -0.02650225, -0.04771684, ...,  0.10757318,\n",
      "          -0.06734398,  0.12334405],\n",
      "         [-0.03929297, -0.03203485,  0.04899918, ...,  0.01970014,\n",
      "          -0.01826341,  0.03253821]]],\n",
      "\n",
      "\n",
      "       [[[-0.0126363 , -0.04802794, -0.09801444, ...,  0.07795355,\n",
      "          -0.02600591, -0.00528505],\n",
      "         [ 0.0275743 , -0.01490961,  0.04323188, ..., -0.04014679,\n",
      "           0.01985082, -0.02430842],\n",
      "         [-0.06109074, -0.10883324, -0.02088339, ..., -0.027899  ,\n",
      "           0.01226298,  0.09262888],\n",
      "         ...,\n",
      "         [-0.06737944,  0.0217963 , -0.03211223, ..., -0.00515806,\n",
      "           0.05198495, -0.04085446],\n",
      "         [ 0.11993785,  0.04152056, -0.08396751, ..., -0.05151276,\n",
      "           0.02254717,  0.03186993],\n",
      "         [-0.00381389,  0.029683  , -0.05655798, ..., -0.07466047,\n",
      "          -0.01920404, -0.00452858]],\n",
      "\n",
      "        [[ 0.04953753, -0.04217187, -0.04113973, ...,  0.06357185,\n",
      "           0.03911582,  0.04492843],\n",
      "         [ 0.04189192, -0.03361606, -0.01176139, ...,  0.04190591,\n",
      "          -0.0060909 , -0.00049222],\n",
      "         [ 0.04671295, -0.01370658,  0.02023679, ..., -0.0518683 ,\n",
      "           0.08226744,  0.06335073],\n",
      "         ...,\n",
      "         [ 0.04224281,  0.05955952, -0.12836847, ...,  0.10381843,\n",
      "           0.09294885,  0.00300576],\n",
      "         [ 0.05375037, -0.07078201, -0.06693758, ..., -0.02874192,\n",
      "           0.00587046, -0.00246377],\n",
      "         [ 0.03863606,  0.01054816, -0.00499939, ..., -0.07893559,\n",
      "           0.01610581, -0.01120867]],\n",
      "\n",
      "        [[-0.02226326, -0.03038529, -0.00428873, ..., -0.03942339,\n",
      "          -0.07955271,  0.05031088],\n",
      "         [-0.05268794, -0.02192756,  0.04234057, ..., -0.01431435,\n",
      "          -0.00043258, -0.02231539],\n",
      "         [ 0.03679287, -0.03625076,  0.04958044, ...,  0.01459602,\n",
      "           0.04914097,  0.09881616],\n",
      "         ...,\n",
      "         [-0.09581197, -0.00338296, -0.08504476, ...,  0.021344  ,\n",
      "           0.00766882,  0.16740808],\n",
      "         [ 0.08598239,  0.10415699, -0.05905177, ..., -0.00274122,\n",
      "          -0.00132462,  0.06461145],\n",
      "         [ 0.04139275,  0.02850255,  0.03667078, ...,  0.00694127,\n",
      "           0.04602962, -0.01803122]]]], dtype=float32), array([-4.66325507e-02,  5.34815667e-03, -5.42725809e-02,  3.72763313e-02,\n",
      "       -3.09783546e-03,  7.35820904e-02,  1.02164872e-01, -6.92289472e-02,\n",
      "        4.30050530e-02, -1.26114056e-01,  6.85569970e-03, -8.30247533e-03,\n",
      "       -1.15094916e-03,  7.62275383e-02, -1.22168921e-02, -2.29385193e-03,\n",
      "        4.78620417e-02,  8.47395733e-02,  4.64179777e-02, -1.22158779e-02,\n",
      "        1.89624801e-02, -6.66306466e-02,  1.92078073e-02, -5.03375605e-02,\n",
      "       -2.95522297e-03,  9.39320400e-02,  7.27779269e-02,  5.29445931e-02,\n",
      "        2.19533383e-03,  5.88121917e-03,  3.08960993e-02,  8.06493163e-02,\n",
      "        4.11384851e-02,  2.37169880e-02,  8.52641165e-02, -2.20839549e-02,\n",
      "        4.92022783e-02,  3.17555219e-02, -3.51554118e-02, -4.62654904e-02,\n",
      "        4.09575365e-02, -4.30350825e-02, -5.70095144e-02, -5.71049415e-02,\n",
      "       -6.02268800e-02, -2.47434862e-02,  2.93913074e-02, -1.41797857e-02,\n",
      "        3.51049267e-02, -1.84627902e-02,  5.94102480e-02, -3.70409973e-02,\n",
      "       -5.62081821e-02,  2.51312517e-02,  2.68034898e-02, -6.52843788e-02,\n",
      "        2.35921144e-02, -7.03080744e-02,  7.38332793e-03,  5.61620258e-02,\n",
      "        1.64798107e-02,  8.50856304e-02,  2.51878295e-02,  9.75377709e-02,\n",
      "       -8.10548663e-03, -9.26993340e-02,  1.15115391e-02, -3.09493691e-02,\n",
      "        1.09919505e-02, -3.20941769e-02, -9.02850404e-02,  3.13699916e-02,\n",
      "       -3.91745977e-02,  1.31828517e-01, -7.40754455e-02,  5.06779999e-02,\n",
      "        1.75860282e-02, -4.85201329e-02, -3.79870902e-03, -1.63718723e-02,\n",
      "        1.52087491e-02, -2.39612870e-02,  1.17031215e-02, -6.28300831e-02,\n",
      "       -5.03968336e-02,  8.38654935e-02,  8.19765851e-02, -1.10734291e-02,\n",
      "        7.09168706e-03,  2.51461733e-02, -2.03737728e-02,  6.92577288e-03,\n",
      "        1.16343051e-02,  5.35124801e-02,  5.88000240e-03, -4.45378423e-02,\n",
      "        1.36285368e-02,  1.07997507e-01,  4.58262451e-02,  1.29110529e-04,\n",
      "        2.70347074e-02,  1.02960698e-01,  4.10657469e-03,  2.75702719e-02,\n",
      "       -1.74206197e-02,  1.28517389e-01, -2.04521627e-03, -3.66386920e-02,\n",
      "       -5.83518781e-02, -1.35295197e-01, -8.45427886e-02,  6.96427301e-02,\n",
      "       -2.79499944e-02,  2.47581787e-02,  4.23058681e-02, -1.75625067e-02,\n",
      "       -3.25973146e-03, -9.02743544e-03, -1.97775085e-02, -7.51328394e-02,\n",
      "       -3.02672479e-02, -1.26844887e-02, -5.56125939e-02, -1.36449269e-03,\n",
      "        1.23243490e-02,  1.23012960e-02, -4.13365066e-02,  4.58657630e-02],\n",
      "      dtype=float32)]\n",
      "\n",
      "Layer: batch_normalization_21\n",
      "Weights: [array([1.0753027 , 1.1068091 , 1.0696179 , 0.9223158 , 0.94170624,\n",
      "       0.8579484 , 0.9911195 , 1.098639  , 0.8777446 , 1.0469694 ,\n",
      "       0.87982523, 0.98625964, 0.9783802 , 1.0100147 , 0.9465708 ,\n",
      "       1.0335965 , 0.99666417, 1.0857009 , 0.9711219 , 0.9411413 ,\n",
      "       0.79320073, 1.019485  , 0.9086276 , 0.96868205, 1.0374147 ,\n",
      "       0.960744  , 0.77947044, 1.0375879 , 1.0942872 , 1.002072  ,\n",
      "       0.8671133 , 0.91210055, 1.0829619 , 0.9481967 , 0.9323398 ,\n",
      "       0.97049457, 0.842245  , 0.8932    , 0.9011779 , 1.2210965 ,\n",
      "       0.9177153 , 0.952696  , 1.1457769 , 1.119223  , 1.0477554 ,\n",
      "       1.0024086 , 0.8628958 , 1.118631  , 1.0200837 , 0.89593387,\n",
      "       0.8432856 , 0.95330024, 1.0136672 , 1.081301  , 0.9813775 ,\n",
      "       0.8993448 , 0.95906186, 1.1689012 , 0.9021556 , 0.95554054,\n",
      "       0.9819767 , 0.9467475 , 1.0327231 , 0.9785016 , 0.91607165,\n",
      "       1.1390095 , 1.2936059 , 1.0355928 , 0.9221815 , 1.0803123 ,\n",
      "       0.94953835, 1.091515  , 0.8965961 , 1.0201191 , 0.9421691 ,\n",
      "       1.0596403 , 0.9149859 , 1.0046209 , 0.9804414 , 0.90635896,\n",
      "       0.9129404 , 0.777349  , 1.1186439 , 0.9196033 , 1.1248804 ,\n",
      "       0.9616969 , 0.8840529 , 1.0399646 , 1.0655857 , 0.9844677 ,\n",
      "       1.070022  , 0.9011287 , 0.95060617, 0.9254969 , 1.0176438 ,\n",
      "       1.1133817 , 1.0322243 , 0.8504778 , 1.1141918 , 1.1389283 ,\n",
      "       1.1424156 , 0.92782456, 0.94876474, 1.0763555 , 0.9626868 ,\n",
      "       0.96908325, 0.90566283, 0.9036048 , 1.0046772 , 1.0369109 ,\n",
      "       1.0957593 , 0.8531179 , 0.9635388 , 0.95137364, 0.94582224,\n",
      "       0.9952704 , 0.9698371 , 1.078897  , 1.2639362 , 1.0615268 ,\n",
      "       1.0678941 , 0.915078  , 0.967413  , 0.98443824, 1.0117326 ,\n",
      "       0.91779554, 1.0290263 , 0.8894512 ], dtype=float32), array([ 4.26350236e-02,  5.08652776e-02,  1.03036210e-01, -3.50499013e-03,\n",
      "       -7.16257747e-03,  1.81702431e-02,  2.23098144e-01,  2.10600197e-01,\n",
      "        1.24360144e-01,  6.64131194e-02,  1.51771829e-01,  8.58620033e-02,\n",
      "        5.10815494e-02,  1.18501104e-01,  1.23825975e-01,  1.10682070e-01,\n",
      "        4.23407331e-02,  1.24752738e-01,  6.98637813e-02,  6.36754259e-02,\n",
      "        1.02499604e-01,  1.13638714e-01,  2.01321006e-01,  2.72628833e-02,\n",
      "        6.16507158e-02,  1.43005893e-01,  2.01993778e-01,  2.88539231e-02,\n",
      "       -1.20661957e-02,  5.34921885e-02,  4.83324006e-02,  1.72750175e-01,\n",
      "        1.42476842e-01,  1.50069132e-01,  8.46814364e-02,  1.01500578e-01,\n",
      "        1.37287840e-01,  7.38311484e-02,  7.86008835e-02,  5.21119684e-02,\n",
      "        7.39771351e-02,  1.14291072e-01,  8.47392082e-02,  3.55799822e-03,\n",
      "        3.33355670e-03,  1.35102198e-01,  9.29140225e-02,  1.43119663e-01,\n",
      "        3.74076404e-02,  1.57369152e-01,  1.55996546e-01,  8.63011256e-02,\n",
      "        1.82610266e-02,  9.94756371e-02,  3.08875497e-02,  2.90602501e-02,\n",
      "        6.79086819e-02,  6.25663921e-02,  1.33798152e-01,  1.54020205e-01,\n",
      "       -6.20160550e-02,  4.52546775e-03,  1.35322869e-01,  5.37830517e-02,\n",
      "        1.63475703e-02, -4.32166196e-02,  3.58215608e-02,  8.92470032e-02,\n",
      "        4.60187234e-02,  2.95378380e-02,  5.69241270e-02,  2.66047250e-02,\n",
      "        6.19201325e-02,  1.67979121e-01,  4.16087061e-02,  2.78186649e-02,\n",
      "        9.84579474e-02,  3.69050503e-02,  8.02952498e-02,  1.33104905e-01,\n",
      "        5.96485101e-02, -4.47657891e-02,  1.13904946e-01,  6.58656880e-02,\n",
      "        1.17192219e-04,  1.40235886e-01,  1.23859882e-01,  1.44796609e-03,\n",
      "        1.51574135e-01,  1.09460942e-01, -1.77624691e-02, -5.88400736e-02,\n",
      "        9.71676707e-02,  2.00074136e-01,  4.66694273e-02,  4.26346473e-02,\n",
      "        5.68610663e-03,  1.94851190e-01, -1.21197335e-01,  8.81172419e-02,\n",
      "        1.38180509e-01,  6.31210953e-02,  8.16271082e-02, -5.63926995e-02,\n",
      "        1.17918765e-02,  9.40303281e-02,  4.44227867e-02,  3.70286480e-02,\n",
      "        7.09786713e-02, -3.58196930e-03, -1.16284937e-01,  1.12560406e-01,\n",
      "        5.83150387e-02,  5.66541925e-02,  1.05633244e-01,  1.34750932e-01,\n",
      "       -1.69299729e-03,  5.39602488e-02, -6.10785037e-02,  3.58859710e-02,\n",
      "        7.92470872e-02,  4.75579835e-02,  6.41090199e-02, -2.70916503e-02,\n",
      "        2.68755443e-02,  5.79761304e-02,  1.19823411e-01,  1.27448231e-01],\n",
      "      dtype=float32), array([0.39729506, 0.28522336, 0.41293412, 1.2059965 , 0.5283374 ,\n",
      "       0.23699963, 0.5107015 , 0.29452798, 0.5874396 , 0.13679606,\n",
      "       0.6295283 , 0.47031114, 0.5446955 , 0.67458105, 0.33063   ,\n",
      "       0.31770205, 0.4989924 , 0.44781587, 0.76695055, 0.57610595,\n",
      "       0.7477104 , 0.47067812, 0.38964927, 0.7032018 , 0.824136  ,\n",
      "       0.20942196, 0.7496951 , 0.28281784, 0.2879432 , 0.34383014,\n",
      "       0.45627686, 0.28299153, 0.37814668, 0.70741564, 0.34003204,\n",
      "       0.20217487, 1.14653   , 0.63492227, 0.60973626, 0.18644552,\n",
      "       0.43349403, 0.4158635 , 0.36374047, 0.19541427, 0.22321723,\n",
      "       0.18733841, 0.8593695 , 0.39695174, 0.41548517, 0.4619034 ,\n",
      "       0.71566725, 0.39147595, 0.35751808, 0.27592042, 0.5175408 ,\n",
      "       0.39597952, 0.518849  , 0.23842151, 0.27142462, 0.45905054,\n",
      "       0.45661926, 0.5837255 , 0.58492476, 0.31334418, 0.24946629,\n",
      "       0.3099311 , 0.16565277, 0.28401974, 0.6552392 , 0.15005173,\n",
      "       0.20061776, 0.48112506, 0.7417695 , 0.70657575, 0.40687394,\n",
      "       0.25314012, 0.24045734, 0.1738759 , 0.4706759 , 0.35208097,\n",
      "       1.0006151 , 0.39932173, 0.30204976, 0.71648914, 0.3834445 ,\n",
      "       1.1047412 , 0.53327835, 0.28276512, 0.73854357, 0.43667063,\n",
      "       0.3119927 , 0.58278453, 0.57329655, 0.7663302 , 0.36230853,\n",
      "       0.30380058, 0.5337564 , 0.9970757 , 0.35623416, 0.2639237 ,\n",
      "       0.17983077, 0.38417748, 0.44378608, 0.35433277, 0.33345863,\n",
      "       0.36684003, 0.40301165, 0.5413854 , 0.32716367, 0.14127249,\n",
      "       0.22897707, 0.83968425, 0.43590724, 0.28971332, 0.3025118 ,\n",
      "       0.62239903, 0.41608617, 0.19069986, 0.18625015, 0.29985753,\n",
      "       0.21267344, 0.44394186, 0.3412494 , 0.6487197 , 0.32746413,\n",
      "       0.8949679 , 0.31899452, 0.48712885], dtype=float32), array([0.7689855 , 0.41950455, 0.7610129 , 2.1576092 , 0.94922304,\n",
      "       0.31225008, 0.6170187 , 0.56299216, 1.0553246 , 0.19360194,\n",
      "       0.9362872 , 0.8010731 , 1.0267748 , 1.1036693 , 0.47777647,\n",
      "       0.366038  , 0.7672674 , 0.6026582 , 1.2836772 , 1.1218373 ,\n",
      "       1.0891887 , 0.7341872 , 0.50343347, 1.3296587 , 1.4583076 ,\n",
      "       0.20093563, 1.036442  , 0.33151954, 0.35676938, 0.66674113,\n",
      "       0.7764216 , 0.3198682 , 0.5910477 , 1.7491134 , 0.45814532,\n",
      "       0.21492699, 2.0005355 , 1.1306924 , 1.0849744 , 0.28846785,\n",
      "       0.7341994 , 0.5052131 , 0.56056887, 0.32987484, 0.32319346,\n",
      "       0.20022127, 1.5051384 , 0.739741  , 0.50101995, 0.6558645 ,\n",
      "       1.1263849 , 0.5696343 , 0.5858122 , 0.34006116, 1.0199369 ,\n",
      "       0.6223205 , 0.67453027, 0.3331664 , 0.42344218, 0.6127033 ,\n",
      "       0.6340448 , 0.82865846, 0.9667875 , 0.36884   , 0.23299852,\n",
      "       0.46007472, 0.22030085, 0.46124065, 1.0703487 , 0.18010144,\n",
      "       0.35977632, 0.8181269 , 1.0797225 , 1.0813009 , 0.69851506,\n",
      "       0.33223104, 0.3041145 , 0.30768064, 1.0164124 , 0.5613634 ,\n",
      "       1.9045784 , 0.6348589 , 0.49322638, 1.1052828 , 0.6732554 ,\n",
      "       1.8683116 , 0.6519336 , 0.4388222 , 1.2838252 , 0.7770394 ,\n",
      "       0.53164876, 0.9678408 , 0.98131347, 1.402121  , 0.5516306 ,\n",
      "       0.48274222, 0.85858816, 1.5445321 , 0.57224375, 0.35523298,\n",
      "       0.21106875, 0.46527213, 0.5672174 , 0.6501975 , 0.46176958,\n",
      "       0.46701157, 0.60022116, 1.216659  , 0.44711253, 0.18416451,\n",
      "       0.3538162 , 1.3091698 , 0.75513864, 0.3204442 , 0.32752877,\n",
      "       1.0718855 , 0.6600905 , 0.19604415, 0.23533791, 0.47515672,\n",
      "       0.33287212, 0.77326703, 0.53187364, 0.9590265 , 0.4450056 ,\n",
      "       1.367367  , 0.4927973 , 0.7239333 ], dtype=float32)]\n",
      "\n",
      "Layer: max_pooling2d_9\n",
      "Weights: []\n",
      "\n",
      "Layer: dropout_13\n",
      "Weights: []\n",
      "\n",
      "Layer: conv2d_18\n",
      "Weights: [array([[[[-1.64931286e-02, -4.95600104e-02,  6.67186379e-02, ...,\n",
      "           3.45065109e-02, -1.00899652e-01, -3.13381851e-02],\n",
      "         [-1.75974425e-03,  5.01787402e-02, -1.13578804e-01, ...,\n",
      "           5.13346083e-02, -1.42807746e-02, -2.85764560e-02],\n",
      "         [ 3.65574956e-02, -4.15226482e-02,  2.63668429e-02, ...,\n",
      "          -2.13866662e-02,  7.97434673e-02, -6.64164498e-02],\n",
      "         ...,\n",
      "         [-1.31356297e-02, -1.67425424e-02, -1.00211844e-01, ...,\n",
      "          -2.94555109e-02,  1.13298818e-02, -3.67914326e-02],\n",
      "         [-3.81825082e-02, -1.08390860e-02, -3.31807323e-02, ...,\n",
      "           1.39320225e-01,  2.06638370e-02, -9.00931284e-03],\n",
      "         [ 3.26877907e-02, -7.64265358e-02, -5.43561876e-02, ...,\n",
      "          -3.64026614e-02, -1.30162844e-02, -2.14764848e-02]],\n",
      "\n",
      "        [[ 7.53331482e-02, -4.82537039e-02,  1.29361702e-02, ...,\n",
      "          -2.11437400e-02, -3.20647508e-02, -3.40587534e-02],\n",
      "         [-4.18115929e-02,  3.48159252e-03, -5.92403635e-02, ...,\n",
      "           6.25464395e-02, -1.11901714e-03, -1.46031916e-01],\n",
      "         [ 5.26419468e-02, -6.18168227e-02, -2.10299529e-02, ...,\n",
      "           3.02907918e-02,  8.15657228e-02,  7.29293562e-03],\n",
      "         ...,\n",
      "         [ 7.41641074e-02, -7.21631758e-03, -3.17479372e-02, ...,\n",
      "          -1.68088097e-02, -7.23868096e-03,  1.25743803e-02],\n",
      "         [-3.85456234e-02,  4.85328995e-02, -1.37555869e-02, ...,\n",
      "           2.69583296e-02,  3.32966074e-02, -3.46479304e-02],\n",
      "         [ 2.49231793e-02, -4.88706604e-02, -2.94905324e-02, ...,\n",
      "          -1.19104376e-02, -3.82456258e-02,  5.87978326e-02]],\n",
      "\n",
      "        [[-5.68263195e-02,  3.44877839e-02,  3.28847058e-02, ...,\n",
      "           1.99486464e-02, -4.17109765e-02,  2.29898207e-02],\n",
      "         [ 7.85415235e-04, -3.84915769e-02, -7.99655169e-02, ...,\n",
      "           1.61799788e-02,  4.27121446e-02, -4.62613106e-02],\n",
      "         [-5.58663567e-04, -9.10390243e-02, -7.78041705e-02, ...,\n",
      "           5.10799289e-02, -5.67056499e-02, -1.34095594e-01],\n",
      "         ...,\n",
      "         [-2.72041634e-02, -1.81264728e-02, -1.04717471e-01, ...,\n",
      "           3.29213850e-02, -7.24036694e-02,  2.12056674e-02],\n",
      "         [ 7.24547803e-02,  7.52888322e-02, -2.71499455e-02, ...,\n",
      "          -8.95154569e-03,  1.12188254e-02,  5.53981736e-02],\n",
      "         [-4.30302396e-02,  1.41904475e-02,  1.00762025e-03, ...,\n",
      "           4.02547717e-02, -1.17846411e-02,  6.97598755e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.29502860e-02,  1.77613162e-02,  1.31265782e-02, ...,\n",
      "          -3.20520476e-02, -8.58377069e-02, -2.62146145e-02],\n",
      "         [ 5.55329807e-02,  1.25283703e-01, -2.13912260e-02, ...,\n",
      "          -1.10749016e-02, -1.74818486e-02, -6.35741800e-02],\n",
      "         [-1.48963812e-03, -2.64421273e-02, -8.12160876e-03, ...,\n",
      "          -5.70821725e-02, -3.25011797e-02, -1.01772718e-01],\n",
      "         ...,\n",
      "         [ 5.34610786e-02,  7.34419227e-02, -5.50502278e-02, ...,\n",
      "          -4.73957621e-02,  1.85293481e-02, -6.95403591e-02],\n",
      "         [-9.31564867e-02, -6.63962588e-02, -1.89104546e-02, ...,\n",
      "          -5.09970486e-02, -1.10744514e-01, -5.00120297e-02],\n",
      "         [-2.78713331e-02,  3.41666653e-03, -5.26282191e-02, ...,\n",
      "          -5.49862199e-02,  2.26460751e-02, -6.70962781e-03]],\n",
      "\n",
      "        [[-8.37962027e-04, -3.54275666e-02,  1.31056849e-02, ...,\n",
      "          -1.05751179e-01, -1.02303065e-01,  1.70906773e-03],\n",
      "         [ 2.54122224e-02,  6.59432486e-02, -2.25357711e-02, ...,\n",
      "          -9.38672200e-02,  1.29171640e-01, -1.02423862e-01],\n",
      "         [ 5.19178547e-02,  5.31586818e-02, -5.24441265e-02, ...,\n",
      "          -2.39533912e-02,  9.12282839e-02,  7.53033310e-02],\n",
      "         ...,\n",
      "         [ 3.34377922e-02, -1.52404830e-02,  1.42971734e-02, ...,\n",
      "          -1.99922230e-02,  4.44511534e-06, -3.26633528e-02],\n",
      "         [-5.20872399e-02,  1.84358843e-02, -1.06812418e-02, ...,\n",
      "           1.08302720e-02, -5.46274930e-02,  5.54923117e-02],\n",
      "         [ 2.53423154e-02, -2.53487006e-02, -8.25807825e-03, ...,\n",
      "           3.02046649e-02,  6.30014986e-02, -4.16241959e-02]],\n",
      "\n",
      "        [[-4.26738523e-02, -5.41141210e-03,  2.45262999e-02, ...,\n",
      "          -6.66601807e-02, -4.64071892e-02, -4.72852103e-02],\n",
      "         [ 3.00916489e-02,  3.71587351e-02, -2.35946774e-02, ...,\n",
      "          -5.90985417e-02,  5.57627864e-02,  1.18915066e-01],\n",
      "         [ 3.57536636e-02,  1.31797865e-02, -5.82855828e-02, ...,\n",
      "           2.69228872e-02,  3.99096683e-02, -1.65484436e-02],\n",
      "         ...,\n",
      "         [ 7.55055388e-03, -1.82914659e-02, -2.19020918e-02, ...,\n",
      "          -5.17759733e-02,  3.94802131e-02, -4.63533076e-03],\n",
      "         [ 1.45543423e-02,  1.36767522e-01, -3.31176110e-02, ...,\n",
      "          -5.43857701e-02, -7.95761310e-03,  9.29373130e-03],\n",
      "         [ 8.91019404e-03, -4.67163175e-02,  3.25591937e-02, ...,\n",
      "           4.91837449e-02, -2.00482477e-02, -1.15874289e-02]]],\n",
      "\n",
      "\n",
      "       [[[-5.07810377e-02, -1.05847672e-01,  1.71914995e-02, ...,\n",
      "          -3.40914563e-03, -4.08227816e-02, -3.64123844e-02],\n",
      "         [ 5.16170589e-03, -6.36112317e-02, -7.39040924e-03, ...,\n",
      "           7.72935972e-02, -5.77322617e-02, -3.48688476e-02],\n",
      "         [-1.07390154e-02,  1.87943596e-02,  2.82442160e-02, ...,\n",
      "          -4.93639708e-02,  9.65407304e-03,  6.15262985e-03],\n",
      "         ...,\n",
      "         [ 3.16786133e-02, -1.18618004e-01, -1.92891061e-02, ...,\n",
      "           7.17062782e-03, -7.26095662e-02, -9.21719596e-02],\n",
      "         [-5.61414510e-02, -8.31270665e-02, -9.57582667e-02, ...,\n",
      "           1.43720058e-03, -1.58324987e-01, -3.98336351e-02],\n",
      "         [ 1.08486004e-02, -3.73515189e-02, -3.92007343e-02, ...,\n",
      "          -7.28116408e-02, -2.51842439e-02, -2.17086207e-02]],\n",
      "\n",
      "        [[-3.98008525e-02, -8.26745033e-02, -2.71628033e-02, ...,\n",
      "          -5.23906276e-02,  7.91942999e-02, -6.93876622e-03],\n",
      "         [-8.66767298e-03, -1.75796170e-02, -6.23685904e-02, ...,\n",
      "           2.07309630e-02, -5.90146706e-02,  2.32855324e-02],\n",
      "         [-9.69451107e-03,  2.40738969e-03,  6.11129217e-02, ...,\n",
      "          -1.08423620e-01,  3.91399562e-02, -9.37558785e-02],\n",
      "         ...,\n",
      "         [-4.67646122e-03, -2.55159922e-02,  1.16471425e-02, ...,\n",
      "          -2.03734916e-02,  7.89055377e-02, -7.32702687e-02],\n",
      "         [-1.13489861e-02, -1.24617346e-01,  1.20658744e-02, ...,\n",
      "          -2.55117789e-02, -6.11080229e-02,  1.03210453e-02],\n",
      "         [-5.96283041e-02,  3.03467810e-02, -1.33661963e-02, ...,\n",
      "          -4.32759058e-03, -5.37622301e-03, -6.27195537e-02]],\n",
      "\n",
      "        [[-3.57143581e-02,  2.56231315e-02,  5.15048355e-02, ...,\n",
      "          -5.35326749e-02,  6.57040849e-02, -4.78092523e-04],\n",
      "         [-3.95172909e-02,  2.83033848e-02, -5.54337054e-02, ...,\n",
      "          -3.85137997e-03,  5.14155738e-02, -1.34963132e-02],\n",
      "         [-1.34776141e-02, -5.93788065e-02, -4.14747521e-02, ...,\n",
      "           2.63031889e-02,  2.13471353e-02, -5.57148121e-02],\n",
      "         ...,\n",
      "         [-5.09180129e-02, -5.41627593e-02,  6.77131675e-03, ...,\n",
      "           8.88105631e-02,  4.03550118e-02,  6.81959093e-02],\n",
      "         [-1.61510203e-02, -5.65364920e-02, -2.57421215e-03, ...,\n",
      "           3.78091000e-02,  3.38469669e-02,  7.89035484e-02],\n",
      "         [ 4.25626338e-02, -6.91904053e-02,  2.82168295e-02, ...,\n",
      "          -3.04511134e-02,  6.79703522e-03,  3.42823900e-02]]]],\n",
      "      dtype=float32), array([ 0.01676046,  0.01348199,  0.04240298, -0.02056725, -0.00815165,\n",
      "        0.05139137, -0.02353784,  0.04461057, -0.04752903,  0.00624253,\n",
      "        0.05111443,  0.00753627,  0.04327901,  0.00758977,  0.03776713,\n",
      "       -0.0767558 ,  0.01962749,  0.00553681, -0.07215589, -0.08774748,\n",
      "        0.05213997, -0.05833328,  0.03264005,  0.05583449,  0.03366666,\n",
      "       -0.03547441,  0.04718302, -0.05646246, -0.11975324,  0.0733365 ,\n",
      "       -0.03160293, -0.19392163, -0.00491257, -0.08149643, -0.05192319,\n",
      "       -0.07566856, -0.0642216 , -0.03893438,  0.03445431,  0.03838862,\n",
      "        0.02565234, -0.06463175,  0.04296895, -0.04622426, -0.0317071 ,\n",
      "        0.12311919, -0.01300237, -0.00830106, -0.06698287, -0.00355753,\n",
      "       -0.1064596 , -0.08738761,  0.0336668 , -0.03707088,  0.05352131,\n",
      "       -0.00487912, -0.18138513, -0.07337907,  0.06581981,  0.02541239,\n",
      "       -0.05165077,  0.0156949 , -0.09415564,  0.0469857 , -0.03161587,\n",
      "       -0.02493375,  0.02884789, -0.04853645,  0.0075315 ,  0.00501664,\n",
      "       -0.1311899 , -0.08901048, -0.06364169, -0.0471061 ,  0.05088629,\n",
      "        0.01695723,  0.00760756,  0.0777495 , -0.01480555, -0.05930483,\n",
      "        0.03803024,  0.00489671, -0.06181515, -0.05307507, -0.03627923,\n",
      "       -0.05807646,  0.01912002,  0.01485978,  0.11243616, -0.05184833,\n",
      "       -0.15890768, -0.01546738, -0.10568244, -0.01034943, -0.02708883,\n",
      "        0.04343999, -0.08029908,  0.03299081, -0.07422993,  0.03884315,\n",
      "        0.04777329,  0.08503035,  0.03067829,  0.0009104 ,  0.06659994,\n",
      "       -0.03766382,  0.0241119 , -0.02680328, -0.05226212, -0.04726578,\n",
      "        0.0927946 , -0.06628535, -0.04489462, -0.11660758, -0.0090213 ,\n",
      "        0.01711495,  0.05542   ,  0.07682578, -0.05975244,  0.00849701,\n",
      "       -0.11769657,  0.04419583,  0.00963247,  0.0456818 , -0.08354385,\n",
      "       -0.04046224,  0.01153103, -0.01036597,  0.0076776 , -0.02012447,\n",
      "        0.05632884, -0.08289307,  0.06375513, -0.06483918,  0.03372214,\n",
      "       -0.03535298,  0.06695321,  0.05576372, -0.04765859, -0.06538655,\n",
      "       -0.08313651, -0.13479841, -0.00303391, -0.02184542,  0.04167635,\n",
      "       -0.06793384, -0.05178313,  0.07235756, -0.01659487, -0.03512728,\n",
      "       -0.0985757 , -0.07319149, -0.00974419, -0.06760614,  0.02039876,\n",
      "       -0.06798721,  0.00248909, -0.05291125,  0.0079405 ,  0.01796986,\n",
      "       -0.04595158, -0.03331487, -0.03370059,  0.06584876, -0.07290197,\n",
      "       -0.05288193, -0.01649731,  0.04024329, -0.03444836, -0.10040507,\n",
      "        0.07542968, -0.04495987, -0.10820294, -0.07891266, -0.09217246,\n",
      "       -0.08562887, -0.11288142, -0.06686334, -0.14079285,  0.00432759,\n",
      "        0.03033227, -0.02440173, -0.00361187,  0.05690522, -0.09862278,\n",
      "        0.01114129, -0.14630143, -0.01770122,  0.07290171,  0.0836384 ,\n",
      "       -0.0952498 , -0.06498407, -0.04179274, -0.01014208, -0.0365377 ,\n",
      "        0.05927675, -0.02744   , -0.04415625, -0.0445333 ,  0.00870131,\n",
      "       -0.02034537, -0.04490342, -0.0025119 ,  0.03190619, -0.09244693,\n",
      "       -0.00288419,  0.01964287, -0.18313424,  0.01558229,  0.01396508,\n",
      "       -0.09208908, -0.10917219,  0.09440477, -0.09807474, -0.02220507,\n",
      "        0.02377073,  0.08674995, -0.1791654 ,  0.04386766,  0.07417584,\n",
      "        0.02434833,  0.04736607, -0.0201085 , -0.18839814, -0.04456883,\n",
      "       -0.01982494, -0.04242902, -0.02071087,  0.02964516,  0.0561155 ,\n",
      "       -0.01179036,  0.00805855, -0.05002053,  0.04050809, -0.04329181,\n",
      "       -0.05635633, -0.06119571, -0.02564985, -0.01093596, -0.06267235,\n",
      "       -0.03136937,  0.09326104, -0.07359765, -0.05636523, -0.04665177,\n",
      "       -0.05266299, -0.00875318, -0.03168488, -0.04676658, -0.04278778,\n",
      "       -0.03137645,  0.03087798, -0.07007151, -0.02078508, -0.0500989 ,\n",
      "       -0.02771961], dtype=float32)]\n",
      "\n",
      "Layer: batch_normalization_22\n",
      "Weights: [array([0.9185325 , 1.0658882 , 0.9345888 , 0.94618756, 0.9979343 ,\n",
      "       1.1304643 , 0.9050975 , 0.8763591 , 1.2782497 , 0.8480359 ,\n",
      "       0.8725529 , 1.143499  , 0.9181899 , 0.9463854 , 0.92617023,\n",
      "       1.0272421 , 0.9338454 , 0.96936977, 0.8621988 , 1.0056858 ,\n",
      "       0.8049246 , 0.9743517 , 0.9459337 , 0.803581  , 0.9389066 ,\n",
      "       0.9848713 , 0.86738837, 1.0475703 , 1.1594522 , 0.8804375 ,\n",
      "       1.0905002 , 1.1226623 , 0.9777571 , 1.0718575 , 1.1372771 ,\n",
      "       1.1561961 , 1.0999454 , 1.0784495 , 1.0227449 , 1.0258904 ,\n",
      "       1.0418016 , 1.0486332 , 0.9403438 , 1.1339617 , 0.94655997,\n",
      "       0.8314224 , 1.0206681 , 0.9695604 , 1.0350752 , 1.124256  ,\n",
      "       1.073374  , 1.0694797 , 0.9954919 , 1.0684373 , 1.0266815 ,\n",
      "       0.9926345 , 0.957577  , 0.9939157 , 0.8791162 , 0.95441747,\n",
      "       1.0468724 , 1.1216354 , 1.094778  , 0.9437879 , 1.0643493 ,\n",
      "       1.0022029 , 0.93783295, 1.1544733 , 0.96882755, 1.0252601 ,\n",
      "       1.1503134 , 1.1457405 , 1.1247362 , 0.93630195, 0.9888037 ,\n",
      "       0.9391365 , 0.89477277, 0.89283854, 0.95153403, 0.9282833 ,\n",
      "       0.94735295, 0.96982664, 1.0153631 , 1.0530986 , 0.9658971 ,\n",
      "       1.0321925 , 0.8540799 , 0.99255174, 0.83623207, 1.0470612 ,\n",
      "       0.9835753 , 0.96084213, 1.0530674 , 0.9965709 , 0.8602984 ,\n",
      "       0.93426085, 1.1355869 , 0.9014375 , 0.944217  , 0.95979416,\n",
      "       0.81713504, 0.861207  , 0.91671795, 1.036457  , 0.9602512 ,\n",
      "       0.91329974, 1.0608865 , 1.0526638 , 1.1331902 , 0.9920927 ,\n",
      "       0.7911558 , 0.99128455, 1.0619847 , 1.0981163 , 0.91571134,\n",
      "       0.82522416, 1.04893   , 0.8638424 , 1.0680748 , 0.89540625,\n",
      "       1.1112133 , 0.9162815 , 0.9658134 , 1.0159928 , 0.9340106 ,\n",
      "       1.0634701 , 0.9172252 , 0.9365562 , 0.94543034, 0.84779525,\n",
      "       0.9409168 , 1.0953312 , 0.98874784, 1.0321639 , 0.974213  ,\n",
      "       1.1807727 , 0.9145416 , 0.9713106 , 1.0133874 , 1.0593042 ,\n",
      "       1.0821093 , 0.972314  , 1.0122466 , 1.001443  , 0.9502809 ,\n",
      "       1.1715791 , 1.047351  , 0.8108513 , 1.016534  , 1.0959646 ,\n",
      "       1.07706   , 0.94804615, 0.950146  , 0.9920843 , 0.94597733,\n",
      "       0.9605992 , 0.8657614 , 1.0847971 , 0.9695941 , 0.94660103,\n",
      "       0.9361582 , 1.0189044 , 1.0299143 , 0.8954441 , 0.9232914 ,\n",
      "       0.98830175, 0.9961629 , 0.8697919 , 1.0881492 , 1.0297819 ,\n",
      "       0.9231986 , 0.8682622 , 0.9599039 , 1.0925274 , 1.0882802 ,\n",
      "       1.1342287 , 1.1120359 , 1.02235   , 1.0834446 , 0.9684584 ,\n",
      "       0.89750093, 0.9222358 , 1.0216489 , 0.907718  , 1.2131432 ,\n",
      "       0.965002  , 0.9939421 , 0.78423566, 0.91894406, 0.8756982 ,\n",
      "       1.026504  , 1.0864879 , 1.0015094 , 0.93675625, 1.0229809 ,\n",
      "       0.87847644, 0.9612788 , 1.0024159 , 0.9321958 , 0.8356961 ,\n",
      "       0.929593  , 1.0583827 , 1.0362756 , 0.87429154, 1.0338017 ,\n",
      "       0.91104335, 1.1484638 , 1.089156  , 0.9109157 , 1.0480474 ,\n",
      "       0.87573004, 1.1004264 , 0.87621653, 1.0699624 , 1.0727737 ,\n",
      "       0.9207976 , 0.9370308 , 1.0471928 , 0.89657795, 0.8907469 ,\n",
      "       0.8841232 , 0.81507677, 1.0481842 , 1.1694524 , 0.9972317 ,\n",
      "       0.89430726, 0.84888846, 1.1537136 , 0.9291318 , 1.1051058 ,\n",
      "       0.9847631 , 1.0171733 , 0.9425011 , 1.0658672 , 1.0518051 ,\n",
      "       1.0652187 , 0.8771749 , 0.89496243, 1.1748205 , 0.9676016 ,\n",
      "       1.0475745 , 0.784133  , 1.2523774 , 0.97437376, 0.8886149 ,\n",
      "       1.0611565 , 0.98491466, 0.9993391 , 1.060777  , 1.0710328 ,\n",
      "       0.8471928 , 0.89113164, 0.9855367 , 1.1378556 , 1.0532341 ,\n",
      "       0.98264754], dtype=float32), array([-0.05042209,  0.09149691,  0.08401078,  0.0207746 ,  0.04687946,\n",
      "        0.03819558, -0.04004857,  0.0149214 ,  0.07464733, -0.02338809,\n",
      "        0.04541674,  0.00529169,  0.03333673,  0.02975378,  0.1429366 ,\n",
      "       -0.04784999,  0.06841493, -0.07838982,  0.02603346, -0.00524299,\n",
      "        0.01137372,  0.03095533, -0.03630526, -0.00860747,  0.11397065,\n",
      "        0.00399802,  0.05910416,  0.00829494,  0.04035962,  0.04930286,\n",
      "        0.09660969,  0.0035011 ,  0.03270704,  0.03247552, -0.01653684,\n",
      "        0.01055458,  0.13367657, -0.03777537,  0.06021329,  0.0993212 ,\n",
      "        0.05999751,  0.00774798,  0.01130291,  0.01711893,  0.03039159,\n",
      "        0.04357087,  0.04238581, -0.02679752,  0.04687302,  0.07783759,\n",
      "        0.00413791, -0.00762173,  0.02737464, -0.02314007,  0.07735624,\n",
      "        0.0134182 ,  0.03293061,  0.02960877, -0.01542183,  0.03569097,\n",
      "        0.03923764,  0.03096327,  0.02926341,  0.03255959,  0.07444711,\n",
      "        0.05814767, -0.00036148, -0.03888143,  0.05709421,  0.00672948,\n",
      "        0.05917428,  0.0204524 , -0.01968449,  0.01974788,  0.06446739,\n",
      "        0.00133292, -0.02911379,  0.02650889,  0.05175453,  0.02934963,\n",
      "        0.02574591,  0.02833472,  0.04826257,  0.00641361,  0.14575182,\n",
      "        0.08380853, -0.00406957,  0.06222359,  0.0505389 ,  0.0170182 ,\n",
      "        0.00082849,  0.05300855,  0.0660385 , -0.02516875,  0.04220778,\n",
      "        0.00394923, -0.10308269,  0.05494572,  0.03625734,  0.00769419,\n",
      "        0.01354722,  0.02833593,  0.04112627, -0.03008331,  0.00913559,\n",
      "        0.04984511,  0.07269663,  0.03417307, -0.01779421,  0.04600979,\n",
      "       -0.05292648, -0.03708745, -0.03799533, -0.09913278,  0.04544652,\n",
      "        0.07870823,  0.11071064,  0.06807917, -0.01467543, -0.0091779 ,\n",
      "        0.00153126, -0.05278022,  0.01421813,  0.05910177,  0.00198624,\n",
      "        0.06793279, -0.01367855,  0.03400465,  0.02966829, -0.03502308,\n",
      "        0.02505629,  0.04560063,  0.02043577,  0.0342117 ,  0.05244973,\n",
      "       -0.08009569,  0.11779083,  0.02906932,  0.15225701, -0.04429519,\n",
      "        0.04688941,  0.0449784 ,  0.08985309, -0.10450831,  0.05191322,\n",
      "        0.04284089, -0.02136152, -0.04488348, -0.01523566,  0.09427655,\n",
      "       -0.00281273,  0.00612731, -0.11696254,  0.07839593,  0.11739921,\n",
      "        0.07030134, -0.05975047,  0.02723762,  0.00076315,  0.0152995 ,\n",
      "        0.00268181,  0.06145446,  0.10316627,  0.08300688, -0.01514245,\n",
      "       -0.07518972,  0.0197316 ,  0.06448703,  0.05855931, -0.02148622,\n",
      "        0.09434143, -0.07920127, -0.00298807,  0.00237221,  0.03185984,\n",
      "       -0.02604569,  0.05297595,  0.06560276,  0.0755605 ,  0.00802763,\n",
      "        0.0637655 ,  0.08131853,  0.0291424 ,  0.14826837,  0.01757991,\n",
      "        0.07398096,  0.07659709, -0.07800127,  0.03265755, -0.00924387,\n",
      "        0.00834913,  0.0780854 ,  0.0260916 ,  0.02934623,  0.00158206,\n",
      "        0.04468789,  0.00836907,  0.03513512, -0.08185877,  0.02616207,\n",
      "       -0.02499612,  0.06403305,  0.04093255,  0.01031256,  0.02031959,\n",
      "       -0.05172942,  0.10890077,  0.02226923, -0.02437655,  0.00456455,\n",
      "       -0.00065572,  0.0582681 , -0.0218167 , -0.0025963 , -0.02585552,\n",
      "        0.05448549,  0.07145277, -0.04143206, -0.0235412 ,  0.06868733,\n",
      "       -0.06375931, -0.10837873,  0.07892618,  0.01424279,  0.09788251,\n",
      "        0.02854693,  0.04624176,  0.04874757, -0.05829364,  0.04893659,\n",
      "        0.04007824, -0.01019692, -0.05120162, -0.02133024, -0.04535516,\n",
      "       -0.02743379, -0.03654582,  0.04036182,  0.03785662,  0.07732446,\n",
      "        0.0535586 ,  0.02080051, -0.03343916,  0.03075496,  0.05233691,\n",
      "       -0.03655595, -0.00489852,  0.0264855 , -0.04361676,  0.05006642,\n",
      "        0.0075959 ,  0.12160602,  0.00399434,  0.05121178,  0.01867645,\n",
      "        0.05688879], dtype=float32), array([2.46976948e+00, 1.17294049e+00, 5.86374402e-01, 5.87043524e-01,\n",
      "       5.83558440e-01, 4.27199155e-01, 2.16157770e+00, 1.50441122e+00,\n",
      "       1.14452951e-01, 9.14732575e-01, 7.38049269e-01, 5.34489870e-01,\n",
      "       9.05206561e-01, 1.17153370e+00, 5.94168007e-01, 1.52437225e-01,\n",
      "       2.91117525e+00, 1.32452011e+00, 9.46919024e-01, 3.75749916e-01,\n",
      "       4.84441757e+00, 4.53109086e-01, 1.28364003e+00, 2.60349321e+00,\n",
      "       1.01613164e+00, 1.05593078e-01, 2.56204391e+00, 5.41375339e-01,\n",
      "       9.12795812e-02, 3.44578338e+00, 6.81577682e-01, 3.11076664e-03,\n",
      "       2.47845912e+00, 2.38587737e-01, 7.09210455e-01, 5.79391979e-02,\n",
      "       2.42915452e-01, 4.49419707e-01, 1.06094348e+00, 1.10633457e+00,\n",
      "       1.20972443e+00, 3.07339966e-01, 1.10382485e+00, 2.93735594e-01,\n",
      "       2.91351944e-01, 3.42924380e+00, 6.05077744e-01, 1.25344741e+00,\n",
      "       3.28689754e-01, 3.85127991e-01, 3.09636772e-01, 5.19877553e-01,\n",
      "       1.17007720e+00, 7.10403323e-01, 6.18599534e-01, 1.06978142e+00,\n",
      "       9.63801593e-02, 1.65842727e-01, 1.26952395e-01, 1.82910252e+00,\n",
      "       6.05796814e-01, 1.68754131e-01, 7.00442910e-01, 2.11869383e+00,\n",
      "       2.21276566e-01, 5.49497008e-01, 1.65431023e+00, 7.94159591e-01,\n",
      "       4.09647137e-01, 9.13841069e-01, 3.29459041e-01, 2.95065373e-01,\n",
      "       2.20098212e-01, 7.31398642e-01, 1.14929903e+00, 3.72919989e+00,\n",
      "       1.54541063e+00, 2.08890295e+00, 7.63066888e-01, 1.06765874e-01,\n",
      "       8.51393104e-01, 1.06429851e+00, 1.11877903e-01, 1.14380491e+00,\n",
      "       1.53285354e-01, 4.24607962e-01, 2.67508888e+00, 1.91871613e-01,\n",
      "       1.91699898e+00, 2.35990167e-01, 7.33044803e-01, 5.87251008e-01,\n",
      "       1.47467062e-01, 1.97355950e+00, 1.36212277e+00, 8.82849932e-01,\n",
      "       2.93387771e-01, 8.17587435e-01, 3.77439596e-02, 1.21299870e-01,\n",
      "       3.98865294e+00, 3.18361735e+00, 1.90736711e+00, 7.09053576e-01,\n",
      "       2.53236860e-01, 4.58508760e-01, 1.37058109e-01, 1.20639944e+00,\n",
      "       5.10515034e-01, 1.49827564e+00, 1.70113385e+00, 1.36473882e+00,\n",
      "       1.13971436e+00, 1.04144067e-01, 1.99855292e+00, 6.68016970e-01,\n",
      "       9.02310431e-01, 4.08141756e+00, 8.02047968e-01, 5.05748451e-01,\n",
      "       2.20436662e-01, 2.74512982e+00, 2.82241762e-01, 2.31659555e+00,\n",
      "       3.07004839e-01, 1.48666680e+00, 1.02583838e+00, 6.98827803e-01,\n",
      "       3.00141513e-01, 1.51483774e-01, 3.01126266e+00, 9.66021121e-01,\n",
      "       2.11638451e+00, 7.43362248e-01, 4.84065354e-01, 8.16666365e-01,\n",
      "       2.40816474e+00, 3.29368258e+00, 3.82116079e-01, 1.21092498e+00,\n",
      "       1.01767622e-01, 1.50783449e-01, 3.65269804e+00, 3.07485014e-01,\n",
      "       1.11197960e+00, 9.21431541e-01, 2.81219840e-01, 1.89685082e+00,\n",
      "       5.02876580e-01, 4.76763666e-01, 5.65360665e-01, 2.38541424e-01,\n",
      "       6.88503385e-01, 7.00605869e-01, 8.63323390e-01, 1.54984578e-01,\n",
      "       1.74855149e+00, 6.83749080e-01, 8.49813223e-01, 2.09862185e+00,\n",
      "       7.53394008e-01, 2.01479364e-02, 2.32197326e-02, 5.64099610e-01,\n",
      "       6.72351792e-02, 1.37705600e+00, 4.05767381e-01, 7.72673845e-01,\n",
      "       2.26556852e-01, 3.58672917e-01, 3.12592673e+00, 4.83157523e-02,\n",
      "       1.29118383e-01, 4.39255327e-01, 4.36982661e-01, 5.71799576e-01,\n",
      "       2.30423331e-01, 2.59396195e-01, 6.68256134e-02, 4.56277460e-01,\n",
      "       6.08165622e-01, 8.63898277e-01, 5.60591936e-01, 7.46063709e-01,\n",
      "       1.57771379e-01, 2.65468192e+00, 1.33276060e-02, 1.94800958e-01,\n",
      "       2.07150126e+00, 1.56148565e+00, 4.82279450e-01, 4.03368294e-01,\n",
      "       5.74210227e-01, 8.72170687e-01, 9.82157290e-01, 1.93151486e+00,\n",
      "       1.12378323e+00, 2.80787915e-01, 5.47779858e-01, 8.05928290e-01,\n",
      "       2.77265221e-01, 2.14107540e-02, 5.06085157e-01, 1.50598538e+00,\n",
      "       3.74536484e-01, 2.97254831e-01, 1.19668198e+00, 1.10436805e-01,\n",
      "       1.52516079e+00, 6.26087725e-01, 8.73981975e-03, 4.58183020e-01,\n",
      "       9.91495609e-01, 9.03325006e-02, 7.53068864e-01, 4.68267024e-01,\n",
      "       7.79015005e-01, 1.70163065e-02, 1.96646297e+00, 4.64084721e+00,\n",
      "       6.55107737e-01, 3.98579121e+00, 3.14680904e-01, 1.56977236e-01,\n",
      "       1.42038271e-01, 3.68043005e-01, 3.51203978e-01, 5.89683354e-01,\n",
      "       1.92695248e+00, 3.43780518e-01, 7.01702595e-01, 1.33830500e+00,\n",
      "       4.88697410e-01, 3.73198211e-01, 2.87839323e-01, 9.45793509e-01,\n",
      "       3.14704850e-02, 1.62281764e+00, 1.82013705e-01, 1.02710880e-01,\n",
      "       4.04008985e-01, 2.57829809e+00, 9.77676138e-02, 8.79842639e-01,\n",
      "       2.02922568e-01, 1.08283031e+00, 5.77950180e-02, 1.42668217e-01,\n",
      "       4.79095191e-01, 2.84981400e-01, 1.34678587e-01, 2.27800107e+00,\n",
      "       4.36309688e-02, 6.08147740e-01, 3.18703681e-01, 2.50921130e-01],\n",
      "      dtype=float32), array([1.42738171e+01, 7.25214434e+00, 3.26242566e+00, 2.66062951e+00,\n",
      "       3.49532151e+00, 2.49200797e+00, 1.17566862e+01, 8.05351830e+00,\n",
      "       5.55607557e-01, 5.28268003e+00, 3.76402473e+00, 2.84721780e+00,\n",
      "       5.11380005e+00, 5.66147041e+00, 3.88147640e+00, 7.20756471e-01,\n",
      "       1.39574184e+01, 6.66839314e+00, 5.23658943e+00, 2.14544654e+00,\n",
      "       1.71794109e+01, 2.56263113e+00, 6.85449886e+00, 1.05692844e+01,\n",
      "       4.34311581e+00, 4.02093202e-01, 1.22150145e+01, 2.75693274e+00,\n",
      "       3.94315898e-01, 1.34101467e+01, 4.33088684e+00, 7.08032958e-03,\n",
      "       1.62844963e+01, 1.18167746e+00, 4.04910183e+00, 2.58914292e-01,\n",
      "       1.04935491e+00, 2.29163527e+00, 5.13943386e+00, 4.68285513e+00,\n",
      "       5.12846375e+00, 1.33125138e+00, 5.06237650e+00, 1.69221556e+00,\n",
      "       1.31449032e+00, 1.77014885e+01, 3.23923802e+00, 8.01101875e+00,\n",
      "       1.90158844e+00, 1.82057786e+00, 1.67972934e+00, 2.93758893e+00,\n",
      "       6.35873652e+00, 3.44980931e+00, 2.75387645e+00, 4.59474707e+00,\n",
      "       4.21556681e-01, 6.57551289e-01, 5.36972582e-01, 9.00015259e+00,\n",
      "       3.13502979e+00, 7.40602851e-01, 4.62954235e+00, 1.10929279e+01,\n",
      "       1.26391470e+00, 3.01394653e+00, 7.66325235e+00, 4.73510790e+00,\n",
      "       1.71461189e+00, 4.96387005e+00, 2.06313038e+00, 1.69766366e+00,\n",
      "       1.09025562e+00, 3.81398535e+00, 5.27195883e+00, 2.03332863e+01,\n",
      "       6.29805422e+00, 9.74653435e+00, 3.60751343e+00, 5.06883085e-01,\n",
      "       4.73633957e+00, 3.56157947e+00, 3.94232094e-01, 5.46676397e+00,\n",
      "       5.55362999e-01, 2.30272365e+00, 1.17400703e+01, 1.04436171e+00,\n",
      "       9.03913498e+00, 1.15295231e+00, 4.50625324e+00, 3.27465701e+00,\n",
      "       7.53387034e-01, 9.83598804e+00, 6.96056557e+00, 3.96837854e+00,\n",
      "       1.77799261e+00, 4.51788282e+00, 1.49643898e-01, 4.16831195e-01,\n",
      "       1.77370167e+01, 1.21487980e+01, 1.22157917e+01, 3.32878804e+00,\n",
      "       1.49165940e+00, 2.46676922e+00, 6.53207242e-01, 7.26961374e+00,\n",
      "       2.47892475e+00, 9.01851082e+00, 8.43815136e+00, 7.29817104e+00,\n",
      "       7.21846104e+00, 4.75817531e-01, 1.03413925e+01, 3.41145182e+00,\n",
      "       5.02003574e+00, 1.77301979e+01, 4.54068613e+00, 2.46921754e+00,\n",
      "       1.04709888e+00, 1.22981749e+01, 1.33174706e+00, 1.45451641e+01,\n",
      "       1.70142066e+00, 9.24721622e+00, 6.57327843e+00, 3.37143350e+00,\n",
      "       1.59711957e+00, 5.83834648e-01, 1.63565750e+01, 6.30502415e+00,\n",
      "       1.01904612e+01, 3.64961219e+00, 2.41531277e+00, 4.48695707e+00,\n",
      "       8.40466595e+00, 1.72006760e+01, 1.83978438e+00, 6.95029354e+00,\n",
      "       4.65896249e-01, 5.87010562e-01, 2.18759270e+01, 1.31252050e+00,\n",
      "       5.70126343e+00, 5.36004782e+00, 1.34758842e+00, 6.36523914e+00,\n",
      "       2.88285065e+00, 2.64307523e+00, 3.21255374e+00, 1.42322171e+00,\n",
      "       3.19097400e+00, 3.60345197e+00, 4.84079552e+00, 5.37583888e-01,\n",
      "       9.27463722e+00, 3.93558002e+00, 5.14951420e+00, 1.27284536e+01,\n",
      "       4.24730349e+00, 5.97004667e-02, 9.23403874e-02, 2.54142356e+00,\n",
      "       2.72710204e-01, 8.76876736e+00, 2.16700292e+00, 3.87991977e+00,\n",
      "       1.13459837e+00, 1.79660797e+00, 1.41927423e+01, 1.46840826e-01,\n",
      "       6.04889810e-01, 2.22983670e+00, 2.17387486e+00, 3.06289411e+00,\n",
      "       1.32470071e+00, 1.42399669e+00, 2.19358489e-01, 1.96035659e+00,\n",
      "       3.43666101e+00, 4.32885170e+00, 3.40822196e+00, 2.75817370e+00,\n",
      "       8.55914712e-01, 1.47517786e+01, 4.08609435e-02, 8.07174981e-01,\n",
      "       1.10478249e+01, 8.52211857e+00, 2.56546545e+00, 2.62101555e+00,\n",
      "       3.51900554e+00, 4.26373053e+00, 6.60100794e+00, 8.37115955e+00,\n",
      "       7.53438663e+00, 1.48643017e+00, 2.54369688e+00, 4.01420593e+00,\n",
      "       1.15882456e+00, 7.65041411e-02, 3.26221466e+00, 7.00833273e+00,\n",
      "       1.88255143e+00, 1.44276452e+00, 5.51677608e+00, 4.83193547e-01,\n",
      "       8.19885254e+00, 3.22739768e+00, 2.01848820e-02, 2.52169132e+00,\n",
      "       4.33136129e+00, 3.88847172e-01, 3.75923371e+00, 2.94925308e+00,\n",
      "       4.25579453e+00, 5.98929077e-02, 1.01835632e+01, 2.28588238e+01,\n",
      "       3.20902920e+00, 2.12562695e+01, 1.51238084e+00, 7.35442758e-01,\n",
      "       7.38461733e-01, 1.53513896e+00, 1.67956650e+00, 2.93925548e+00,\n",
      "       9.27271652e+00, 1.86021686e+00, 3.45883799e+00, 7.83649731e+00,\n",
      "       2.44198680e+00, 2.19770670e+00, 1.29321826e+00, 6.29037619e+00,\n",
      "       1.04123838e-01, 8.57824707e+00, 1.01054454e+00, 2.89269269e-01,\n",
      "       1.76383519e+00, 1.19210129e+01, 5.01302063e-01, 5.05770111e+00,\n",
      "       8.32666814e-01, 5.86635113e+00, 2.30444446e-01, 5.77545404e-01,\n",
      "       1.98426414e+00, 1.35715973e+00, 4.97709244e-01, 9.82101536e+00,\n",
      "       1.51431307e-01, 2.70648360e+00, 1.51805997e+00, 9.40134704e-01],\n",
      "      dtype=float32)]\n",
      "\n",
      "Layer: max_pooling2d_10\n",
      "Weights: []\n",
      "\n",
      "Layer: dropout_14\n",
      "Weights: []\n",
      "\n",
      "Layer: flatten_2\n",
      "Weights: []\n",
      "\n",
      "Layer: dense_6\n",
      "Weights: [array([[-0.01374611,  0.00456418, -0.04090416, ...,  0.01773144,\n",
      "        -0.02220425,  0.04915558],\n",
      "       [-0.00850637, -0.0767994 ,  0.02878884, ..., -0.02753126,\n",
      "         0.02463607,  0.01910739],\n",
      "       [ 0.01804155, -0.06170966, -0.06367474, ..., -0.01597432,\n",
      "        -0.02946626,  0.01480275],\n",
      "       ...,\n",
      "       [-0.03575652, -0.11843839, -0.01135861, ..., -0.02544407,\n",
      "        -0.03141161, -0.07704984],\n",
      "       [-0.02164598,  0.031002  , -0.02701214, ..., -0.00190522,\n",
      "        -0.07472807, -0.00909677],\n",
      "       [-0.0007791 , -0.00365255,  0.0152697 , ..., -0.02360746,\n",
      "         0.00153966, -0.06616659]], dtype=float32), array([-0.00804167,  0.06259359,  0.02026   ,  0.03572964, -0.09823532,\n",
      "        0.03203256,  0.00481957,  0.08861529, -0.00449199,  0.03012732,\n",
      "        0.03451733, -0.02755976,  0.07671896, -0.00836267, -0.01774156,\n",
      "       -0.05547476, -0.05002217, -0.0333288 , -0.04196978, -0.00826671,\n",
      "       -0.00548795,  0.00537412, -0.01924513,  0.01962095,  0.08478796,\n",
      "       -0.0111526 ,  0.04865928, -0.03129273,  0.1086714 ,  0.007047  ,\n",
      "        0.02447156,  0.0484362 , -0.04444911, -0.02737808,  0.00011238,\n",
      "        0.01712867, -0.04010791,  0.00049686,  0.10674906, -0.01142664,\n",
      "       -0.03551799, -0.00299856,  0.02159598, -0.01714624, -0.02428097,\n",
      "        0.01107996, -0.01685471,  0.09859854, -0.01611468,  0.02310824,\n",
      "       -0.03180298, -0.06360511,  0.07615034, -0.04010356, -0.04910699,\n",
      "        0.01383459,  0.0489447 ,  0.00427356, -0.01397639, -0.02720973,\n",
      "        0.0352954 ,  0.05434832,  0.05364073, -0.04153963, -0.00288109,\n",
      "        0.02773918,  0.02978896, -0.03293939, -0.03999824, -0.03684487,\n",
      "        0.01439322,  0.0687158 ,  0.01125922,  0.0361299 ,  0.05742494,\n",
      "        0.02461014,  0.0938065 , -0.02736617,  0.03410437,  0.08373293,\n",
      "       -0.01454051, -0.03552661, -0.01109657,  0.03439591,  0.02682156,\n",
      "        0.0031703 , -0.05689752, -0.0082485 ,  0.00818353,  0.06472582,\n",
      "       -0.04793131,  0.02300936, -0.00955232, -0.02113702, -0.00957967,\n",
      "        0.002929  , -0.01856354, -0.02495703,  0.07894939, -0.05849323,\n",
      "        0.02666243, -0.00830071,  0.00442744,  0.0011204 ,  0.01433344,\n",
      "       -0.02849793,  0.03315627, -0.01464414,  0.06329595, -0.00825355,\n",
      "       -0.01734366, -0.01455398, -0.01114449, -0.00524403, -0.04299199,\n",
      "       -0.01126847,  0.0578111 , -0.04907458,  0.03612049,  0.0404753 ,\n",
      "        0.05329036,  0.0395395 , -0.01889777,  0.03836205,  0.02080842,\n",
      "        0.0211236 , -0.01919364, -0.01600029, -0.07126928, -0.02007958,\n",
      "       -0.02993677,  0.01544987, -0.05102433, -0.04193018, -0.03531522,\n",
      "       -0.00065215, -0.01866808, -0.0405242 ,  0.00993815, -0.00810378,\n",
      "        0.03376023,  0.0048953 , -0.02952013, -0.05891014, -0.03297861,\n",
      "       -0.06164455, -0.10398202, -0.07783981, -0.0477532 ,  0.05453218,\n",
      "        0.04259313,  0.0373181 ,  0.04503619,  0.00418918,  0.01030471,\n",
      "       -0.06736404,  0.01116148, -0.0172401 , -0.054972  ,  0.0556553 ,\n",
      "        0.04446063, -0.01118647,  0.01938269,  0.03941644, -0.04817792,\n",
      "       -0.00200212,  0.00655108,  0.02675262,  0.02002875, -0.02379347,\n",
      "       -0.01589292, -0.04116449, -0.02017524, -0.02737615, -0.06680264,\n",
      "        0.01963407,  0.03045385, -0.00972731, -0.01905573, -0.02798298,\n",
      "        0.0572039 ,  0.03191971, -0.0072757 ,  0.03861149,  0.02623882,\n",
      "       -0.05169496,  0.0176297 , -0.00602385, -0.0048297 ,  0.03137747,\n",
      "       -0.00212046, -0.00818734, -0.01431276,  0.00469635, -0.0361471 ,\n",
      "        0.02017949, -0.01843807, -0.00503747,  0.02515924,  0.08060856,\n",
      "       -0.03744897,  0.04268061,  0.02547126, -0.01682793, -0.02875804,\n",
      "        0.00475843, -0.01936089, -0.02679194,  0.01190426,  0.00723269,\n",
      "       -0.0176105 ,  0.05154728, -0.00030101, -0.03953709,  0.02387706,\n",
      "       -0.01732335, -0.01551241, -0.0041467 , -0.00527655, -0.01801351,\n",
      "       -0.04808413, -0.00505366,  0.05819142,  0.01017817,  0.04837157,\n",
      "        0.02251332,  0.02769546, -0.03147042, -0.00659665,  0.00249062,\n",
      "        0.00897058,  0.0260315 ,  0.04788685,  0.00399296, -0.02793488,\n",
      "        0.02653318, -0.02019762,  0.01926953, -0.02084944, -0.01989633,\n",
      "        0.01424461, -0.01644375, -0.04070415, -0.01392076, -0.04763169,\n",
      "        0.02678377, -0.01586669, -0.07111724,  0.055235  ,  0.00261839,\n",
      "        0.03489876, -0.00898632,  0.04287122, -0.02612662, -0.03702391,\n",
      "        0.02598779], dtype=float32)]\n",
      "\n",
      "Layer: batch_normalization_23\n",
      "Weights: [array([0.95137334, 0.92307305, 0.81746083, 0.8822389 , 0.8631949 ,\n",
      "       0.83862   , 0.88348246, 0.85923254, 0.85602194, 0.839267  ,\n",
      "       0.8499013 , 0.91631395, 0.83964485, 0.74773073, 0.9201745 ,\n",
      "       0.85635436, 0.8280227 , 0.82534033, 0.8476223 , 0.80415934,\n",
      "       0.9635926 , 0.8331528 , 0.9492319 , 0.84819394, 0.8028275 ,\n",
      "       1.0022928 , 0.9489405 , 0.8977001 , 0.8173309 , 0.8895836 ,\n",
      "       0.8140327 , 0.8508438 , 0.9876848 , 0.83464736, 0.8454733 ,\n",
      "       0.84316206, 0.7639073 , 0.8692025 , 0.844491  , 0.86789036,\n",
      "       0.8443184 , 0.8026997 , 0.92750937, 0.90417624, 0.79753935,\n",
      "       0.8662253 , 0.92636055, 0.8554414 , 0.8969402 , 0.8339432 ,\n",
      "       0.8593834 , 0.9411077 , 0.82687163, 0.7772745 , 0.8543454 ,\n",
      "       0.8542695 , 0.813881  , 0.84199566, 0.9452335 , 0.91131413,\n",
      "       0.8007136 , 0.84894717, 0.8752169 , 0.71949625, 0.8754168 ,\n",
      "       0.79663056, 0.8702475 , 0.92854047, 0.8531975 , 0.8689679 ,\n",
      "       0.85799116, 0.8629216 , 0.87721133, 0.86923355, 0.83017397,\n",
      "       0.8765822 , 0.85994464, 0.75554025, 0.8649941 , 0.9090505 ,\n",
      "       0.85250556, 0.92552125, 0.8792257 , 0.8428588 , 0.8739014 ,\n",
      "       0.83195275, 0.9290701 , 0.7530222 , 0.79467154, 0.82878864,\n",
      "       0.841198  , 0.8420237 , 1.0093998 , 0.89803326, 0.8829051 ,\n",
      "       0.8260665 , 0.9760193 , 1.0433981 , 0.8624296 , 0.8771677 ,\n",
      "       0.8531014 , 0.95970905, 0.77428955, 0.8388985 , 0.836128  ,\n",
      "       0.97548306, 0.81713617, 0.866229  , 0.8527719 , 0.8402175 ,\n",
      "       0.8839674 , 0.9863242 , 0.8885189 , 1.0413188 , 0.7430827 ,\n",
      "       0.8084427 , 0.82739913, 0.8920761 , 0.8559428 , 0.8826844 ,\n",
      "       0.8189454 , 0.8330255 , 0.97169006, 0.7396854 , 0.8335012 ,\n",
      "       0.84343535, 0.91059786, 0.99375033, 0.9181415 , 0.9370521 ,\n",
      "       0.9487229 , 0.8169389 , 0.78032994, 0.8169788 , 0.895324  ,\n",
      "       0.7990678 , 0.8722342 , 0.91051835, 0.8908487 , 0.9702511 ,\n",
      "       0.88540375, 0.92309576, 0.84883064, 0.9236821 , 0.84950525,\n",
      "       0.98380095, 0.88143015, 0.9040046 , 0.9910747 , 0.8234111 ,\n",
      "       0.8475797 , 0.7057971 , 0.8542194 , 0.82998145, 0.8631854 ,\n",
      "       0.751935  , 0.83457357, 0.8120588 , 0.9042332 , 0.87310284,\n",
      "       0.85823774, 0.9227666 , 0.8210505 , 0.8142694 , 0.8636656 ,\n",
      "       0.77058446, 0.8636279 , 0.769315  , 0.7980536 , 0.9123235 ,\n",
      "       0.894238  , 0.97184724, 0.72397155, 0.9078052 , 0.72823083,\n",
      "       0.819724  , 0.7466395 , 0.9359836 , 0.8675233 , 0.8713459 ,\n",
      "       0.8723042 , 0.83626866, 0.899445  , 0.83577144, 0.8295311 ,\n",
      "       0.84751856, 0.8737396 , 0.8429733 , 0.8431769 , 0.80861336,\n",
      "       0.83491033, 0.86193115, 0.74270475, 0.8443166 , 0.89041245,\n",
      "       0.7894817 , 0.97952163, 0.9385793 , 0.834267  , 0.86815226,\n",
      "       0.8806275 , 0.8025669 , 0.8479003 , 0.980418  , 0.867264  ,\n",
      "       0.8073799 , 0.98539966, 0.8344157 , 0.8508209 , 0.8611667 ,\n",
      "       0.8618645 , 0.80986506, 0.81911665, 0.8528365 , 0.7894866 ,\n",
      "       0.7800968 , 0.7954153 , 0.80798006, 0.81663114, 0.73095554,\n",
      "       0.8966349 , 0.9030635 , 0.9162745 , 0.89875734, 0.86799383,\n",
      "       0.8462469 , 0.87120575, 0.7041877 , 1.0165983 , 0.7863343 ,\n",
      "       0.78507525, 0.82566667, 0.83631164, 0.813955  , 0.946549  ,\n",
      "       0.655105  , 0.9254275 , 0.86983913, 0.9688197 , 0.7892631 ,\n",
      "       0.846881  , 0.954614  , 0.97528106, 0.95383656, 0.91798645,\n",
      "       0.83754337, 0.90470093, 0.85976005, 0.8489098 , 0.78046036,\n",
      "       0.8891942 , 0.97429645, 0.8447659 , 0.9409939 , 0.8819525 ,\n",
      "       0.8262531 ], dtype=float32), array([-0.10839125, -0.02470235, -0.05388765,  0.04729236, -0.14392468,\n",
      "        0.14808811,  0.06421426,  0.08609396, -0.01930158,  0.03141566,\n",
      "       -0.18113717, -0.14740957, -0.01369146, -0.01722623,  0.00165353,\n",
      "       -0.11607579, -0.0893538 , -0.04112519, -0.02737603, -0.10931998,\n",
      "       -0.08698784, -0.0325203 ,  0.07959849,  0.07435293,  0.08809018,\n",
      "        0.00138548,  0.00247741,  0.07832002,  0.04400688, -0.15378384,\n",
      "        0.03151412, -0.01693273, -0.0846707 ,  0.00396647,  0.10978938,\n",
      "       -0.14614484,  0.11478455,  0.17052053,  0.04217304, -0.12997165,\n",
      "       -0.02258985, -0.08954708,  0.0699921 , -0.01672636,  0.03298308,\n",
      "        0.02374727, -0.01031381,  0.08218996, -0.01263643,  0.01391837,\n",
      "       -0.02221394,  0.1753371 , -0.00734423, -0.02819405,  0.02394154,\n",
      "        0.13799098, -0.03084465, -0.02871133,  0.03034192, -0.15675654,\n",
      "        0.20113336, -0.01295779,  0.10846557, -0.08875237, -0.11658195,\n",
      "       -0.12372839,  0.12768358, -0.00395666, -0.04238039, -0.17142469,\n",
      "       -0.13663584,  0.12735385,  0.0831332 , -0.14184172,  0.15263958,\n",
      "       -0.11665978,  0.03304422, -0.11419427, -0.19341844, -0.03652762,\n",
      "        0.12269142, -0.06921685,  0.11351068,  0.16935976, -0.1516741 ,\n",
      "       -0.0212237 , -0.04247802, -0.12131988,  0.02538627,  0.11462083,\n",
      "       -0.05084406, -0.08790404,  0.1753272 ,  0.0069745 , -0.09319173,\n",
      "       -0.08589549, -0.18083917,  0.08177492,  0.07926953, -0.17568915,\n",
      "       -0.02102891, -0.13659626,  0.02178827,  0.03246668,  0.06156123,\n",
      "        0.04135388,  0.13436984, -0.13573958,  0.09355055,  0.18379514,\n",
      "       -0.05011155,  0.08278093,  0.04283236,  0.09657235, -0.01368836,\n",
      "       -0.10207962,  0.0037034 ,  0.08880594,  0.20722257,  0.14793316,\n",
      "        0.04614792, -0.08508086,  0.01491685, -0.07310061,  0.11773803,\n",
      "        0.02835699, -0.13393046,  0.16298835, -0.08952615, -0.08787335,\n",
      "       -0.24911968,  0.04795149, -0.12013165,  0.08216503,  0.00577114,\n",
      "       -0.09705406, -0.09641668, -0.07671423, -0.08692203, -0.16388151,\n",
      "       -0.0960762 ,  0.19097775, -0.04017916, -0.0767221 , -0.05404776,\n",
      "       -0.03553958, -0.14729671,  0.14424536,  0.05064725,  0.03961462,\n",
      "        0.08258534, -0.07970469, -0.06254476,  0.0744726 , -0.08771205,\n",
      "        0.04828067, -0.11387228, -0.1380841 , -0.07392376,  0.02118082,\n",
      "       -0.16868795,  0.06100359,  0.10729638,  0.00770543,  0.06305274,\n",
      "       -0.01425043, -0.14920789,  0.04016392,  0.02940299,  0.00558075,\n",
      "        0.04189955,  0.08761901, -0.03107389,  0.165449  , -0.03747848,\n",
      "       -0.07186945,  0.01040579, -0.05707174, -0.0400643 ,  0.08554636,\n",
      "        0.03749681,  0.13064384, -0.00824917,  0.07975382,  0.17116241,\n",
      "       -0.08530108, -0.11809844,  0.0840258 ,  0.06024983,  0.21566693,\n",
      "       -0.05575622, -0.05414089,  0.0457822 ,  0.08182635, -0.07408523,\n",
      "       -0.13259935,  0.2058767 , -0.05790192,  0.10292356,  0.20008281,\n",
      "       -0.19826506,  0.09993865,  0.06891248, -0.09298559,  0.03621195,\n",
      "       -0.03368875, -0.09636508, -0.21534309,  0.1332485 ,  0.01886624,\n",
      "       -0.04665592,  0.03928349,  0.15816966,  0.09843244,  0.01165892,\n",
      "       -0.10547934,  0.15607244, -0.13224477,  0.01006347,  0.06629768,\n",
      "       -0.12459765,  0.04175526, -0.03426957, -0.03534279,  0.07069803,\n",
      "       -0.13731198, -0.05319871, -0.03467482,  0.06505959, -0.1680692 ,\n",
      "       -0.1075461 ,  0.10022306,  0.14239278, -0.12424652,  0.09383592,\n",
      "        0.14897884, -0.11696365, -0.145643  , -0.10110417,  0.05090195,\n",
      "        0.08265248,  0.14168468, -0.10033609,  0.05023402,  0.00623672,\n",
      "       -0.06674112, -0.01992459, -0.00204652,  0.15341568,  0.0934609 ,\n",
      "       -0.07065877, -0.05741645,  0.05814091, -0.07431593, -0.08733122,\n",
      "        0.10725779], dtype=float32), array([5.88263493e-10, 1.85449810e+01, 2.11338501e+01, 3.93803558e+01,\n",
      "       3.99641402e-04, 3.44831161e+01, 2.74962673e+01, 5.15228539e+01,\n",
      "       1.59587326e+01, 2.65225716e+01, 8.93181133e+00, 7.49613371e-13,\n",
      "       3.11543961e+01, 5.47283125e+00, 1.80788327e-12, 1.44411344e-03,\n",
      "       2.61396915e-03, 1.92157477e-05, 5.19714156e-08, 9.81166267e+00,\n",
      "       5.98774242e-12, 4.08065033e+00, 3.44908520e-12, 4.00506668e+01,\n",
      "       2.75972862e+01, 4.16965426e-13, 1.46588726e+01, 3.97743755e-10,\n",
      "       2.77535419e+01, 1.43574238e+01, 2.26510773e+01, 1.82215900e+01,\n",
      "       1.37113584e-11, 1.49318844e-01, 2.93761019e-07, 7.61614084e+00,\n",
      "       8.86252594e+00, 1.94998531e+01, 4.57980385e+01, 5.53495693e+00,\n",
      "       6.77908077e-11, 1.48332567e+01, 9.74304199e+00, 7.02244794e-13,\n",
      "       5.59178162e+00, 9.51437664e+00, 1.07588903e-11, 2.35374012e+01,\n",
      "       2.00546909e-13, 6.34639263e+00, 2.07015946e-10, 6.55070562e-13,\n",
      "       3.15125408e+01, 1.77686510e-04, 6.88785349e-07, 4.46824417e+01,\n",
      "       2.16173954e+01, 1.63371372e+01, 6.67362172e-12, 9.51997422e-12,\n",
      "       5.12998238e+01, 2.37152901e+01, 1.95828419e+01, 5.20400085e+01,\n",
      "       1.55062509e+00, 1.33087482e+01, 2.14885921e+01, 1.19508223e-11,\n",
      "       3.35925788e-01, 2.39568108e-04, 8.84029865e+00, 2.11133060e+01,\n",
      "       4.58644621e-07, 2.34139042e+01, 2.62659473e+01, 1.70481777e+01,\n",
      "       3.66438370e+01, 5.25253344e+00, 2.93607140e+00, 2.30768585e+01,\n",
      "       1.62638436e-12, 3.40189487e-12, 1.10109686e-03, 4.19025192e+01,\n",
      "       3.62921181e+01, 1.65219570e-03, 8.69256382e-08, 1.34478569e+01,\n",
      "       6.70441771e+00, 2.46862793e+01, 2.19197842e-04, 7.57036734e+00,\n",
      "       4.15140497e-13, 2.18674791e-06, 1.01416390e-12, 9.10139084e+00,\n",
      "       6.28928376e-12, 3.69637177e-12, 2.55174637e+01, 1.07622213e-08,\n",
      "       2.15115910e+01, 2.87108987e-13, 2.24671726e+01, 3.08202052e+00,\n",
      "       3.20458107e+01, 1.33863658e-11, 3.12589741e+01, 7.03029457e-07,\n",
      "       5.13725815e+01, 6.99849176e+00, 3.86929489e-03, 2.47983708e-12,\n",
      "       5.82504271e-12, 3.51964063e-13, 9.64665699e+00, 2.64969647e-01,\n",
      "       1.54575891e+01, 1.80412577e-11, 4.72702484e+01, 4.40665894e+01,\n",
      "       2.02708969e+01, 1.84257145e+01, 1.72560664e-11, 2.01004601e+01,\n",
      "       3.27803459e+01, 1.37407885e+01, 1.09305086e+01, 6.34025872e-13,\n",
      "       4.00418060e-10, 5.79414283e-13, 4.42469195e-12, 2.35794144e+01,\n",
      "       2.69981101e-04, 2.99195548e-08, 1.66187161e-10, 1.57811041e+01,\n",
      "       8.79454383e-05, 2.56441725e-11, 1.77684383e+01, 4.84535936e-12,\n",
      "       1.39022007e+01, 1.19512062e-08, 4.21488693e-07, 1.91732116e-10,\n",
      "       3.51904984e+01, 4.50760089e-12, 4.98096488e-05, 2.05413897e-07,\n",
      "       5.28095905e-13, 1.32718973e+01, 1.82386303e+01, 1.62606087e+01,\n",
      "       3.57259903e+01, 1.54837017e+01, 2.99779129e+00, 4.28359071e-03,\n",
      "       4.37506008e+00, 4.18785821e-05, 4.66611423e-03, 2.80912304e+01,\n",
      "       1.37505951e+01, 2.31482460e-07, 3.09622669e+01, 1.83476696e+01,\n",
      "       1.73302680e-01, 1.53563023e+01, 1.11943474e+01, 1.61679859e+01,\n",
      "       5.28880405e+00, 1.14757752e-11, 2.49570221e-05, 8.19676141e-13,\n",
      "       3.52197723e+01, 1.06293534e-08, 6.08314610e+00, 2.38384056e+01,\n",
      "       1.09683590e+01, 1.43700102e-12, 3.12562310e-03, 5.04389308e-10,\n",
      "       1.68976669e+01, 2.79211197e+01, 1.16400487e-12, 6.14933825e+00,\n",
      "       4.38868599e+01, 1.42932148e-03, 1.41903229e+01, 5.64959955e+00,\n",
      "       5.44813403e-04, 4.94052734e+01, 1.76213495e-02, 4.12173681e-12,\n",
      "       2.49243755e+01, 2.17827015e+01, 5.48549428e-09, 3.01895924e+01,\n",
      "       6.37345428e-13, 1.08500301e-11, 3.38380585e+01, 4.41678925e+01,\n",
      "       3.28720037e-11, 8.07443237e+00, 2.44794798e+00, 7.08696166e-12,\n",
      "       8.62534534e-07, 2.81208210e+01, 5.73543220e-13, 6.12826869e-02,\n",
      "       4.85325851e+01, 1.82715454e+01, 7.29062449e-05, 1.66220551e+01,\n",
      "       1.41335917e+01, 8.43042564e+00, 1.86569557e+01, 6.65951014e+00,\n",
      "       6.03368711e+00, 1.45129700e+01, 8.13407516e+00, 1.23876047e+01,\n",
      "       1.17024543e-10, 5.00249428e-07, 1.45266094e+01, 8.41288185e+00,\n",
      "       2.16066322e+01, 3.01893559e+01, 1.97495689e+01, 9.59701717e-01,\n",
      "       4.01341417e-12, 9.42796993e+00, 1.22478247e+01, 3.12352142e+01,\n",
      "       1.20096216e+01, 1.14592053e-01, 5.43561593e-12, 7.77790070e+01,\n",
      "       4.99210430e-11, 3.91101341e+01, 2.24484754e-11, 3.87555957e+00,\n",
      "       1.44906263e+01, 3.89934802e-13, 5.17709868e-11, 8.73477592e-12,\n",
      "       7.70374270e-13, 1.38253202e+01, 3.33729458e+00, 6.85295754e-06,\n",
      "       5.67391472e+01, 5.30566101e+01, 7.61534405e+00, 4.10675807e-13,\n",
      "       3.49873123e+01, 6.17649649e-13, 1.40324985e-09, 2.34898434e+01],\n",
      "      dtype=float32), array([6.68496813e-09, 3.12227112e+02, 2.67392334e+02, 4.21516968e+02,\n",
      "       1.92451442e-03, 3.62293457e+02, 4.70957825e+02, 4.10303772e+02,\n",
      "       2.81460083e+02, 2.86850494e+02, 1.76485748e+02, 4.20869719e-12,\n",
      "       3.19720490e+02, 1.04179726e+02, 2.13324098e-11, 2.18810588e-02,\n",
      "       1.28903827e-02, 6.24974637e-05, 7.51218010e-07, 1.43629944e+02,\n",
      "       1.61356432e-11, 8.22730179e+01, 4.02951153e-12, 2.45060989e+02,\n",
      "       2.56722778e+02, 1.45845760e-12, 2.96537872e+02, 9.22766641e-10,\n",
      "       2.72838959e+02, 3.32561401e+02, 3.39428986e+02, 2.90191254e+02,\n",
      "       8.32304017e-11, 2.76329303e+00, 2.17293291e-07, 1.31146317e+02,\n",
      "       2.36076218e+02, 2.86823151e+02, 3.65242950e+02, 1.64736923e+02,\n",
      "       3.91437105e-10, 2.52221695e+02, 2.55423920e+02, 3.69678203e-12,\n",
      "       9.60446167e+01, 1.35933701e+02, 5.09946460e-11, 3.25799225e+02,\n",
      "       3.37539404e-13, 1.60941864e+02, 1.68444458e-09, 2.55986660e-12,\n",
      "       3.49291809e+02, 3.95158352e-03, 2.59547323e-06, 3.43092957e+02,\n",
      "       2.26723038e+02, 2.69302582e+02, 2.00101203e-11, 3.24159900e-11,\n",
      "       3.15335114e+02, 2.63838287e+02, 2.67621521e+02, 4.49918030e+02,\n",
      "       3.04066200e+01, 1.83568024e+02, 2.90100006e+02, 6.30154540e-11,\n",
      "       6.15410852e+00, 3.29218688e-04, 1.37114197e+02, 2.56790436e+02,\n",
      "       3.38314521e-07, 3.76806671e+02, 2.79277863e+02, 2.53696701e+02,\n",
      "       3.86650696e+02, 1.03123688e+02, 6.36683197e+01, 3.47716644e+02,\n",
      "       1.07796350e-11, 3.34494780e-12, 1.27777169e-02, 4.24327484e+02,\n",
      "       5.08580536e+02, 2.13241968e-02, 2.94678006e-08, 2.13973312e+02,\n",
      "       1.59837448e+02, 3.25283203e+02, 1.45834591e-03, 1.46994156e+02,\n",
      "       1.44573123e-12, 6.41371071e-06, 6.55459107e-12, 1.23619865e+02,\n",
      "       1.76492640e-11, 3.97030542e-12, 2.65840149e+02, 1.05206823e-07,\n",
      "       3.09186615e+02, 6.91496502e-13, 1.69361725e+02, 4.78821564e+01,\n",
      "       4.65018860e+02, 7.03675312e-11, 3.23287781e+02, 3.19776450e-06,\n",
      "       3.72277100e+02, 1.37053711e+02, 4.75610383e-02, 2.99683607e-12,\n",
      "       1.50772346e-11, 1.03918003e-12, 1.41089569e+02, 3.69403338e+00,\n",
      "       2.20300293e+02, 7.78003703e-11, 3.98554657e+02, 5.24894714e+02,\n",
      "       2.75679779e+02, 1.78704208e+02, 3.93266981e-11, 1.60866547e+02,\n",
      "       3.46869476e+02, 1.50224808e+02, 2.79628479e+02, 3.10455763e-12,\n",
      "       3.81468590e-09, 2.81625309e-12, 4.87689793e-12, 3.77205475e+02,\n",
      "       7.10828463e-04, 3.04237403e-07, 1.81757415e-10, 3.12702362e+02,\n",
      "       1.45651482e-03, 1.87083876e-10, 4.07830353e+02, 1.08115418e-11,\n",
      "       2.84046448e+02, 4.91899819e-08, 1.14156328e-05, 6.75355660e-10,\n",
      "       4.34932861e+02, 4.57516403e-12, 7.92002946e-04, 4.06983008e-06,\n",
      "       2.33950489e-12, 1.85161133e+02, 2.75760925e+02, 4.01244263e+02,\n",
      "       3.95066895e+02, 2.41130951e+02, 7.03482742e+01, 5.24829514e-02,\n",
      "       8.71481400e+01, 9.48411471e-05, 4.03946489e-02, 3.19639160e+02,\n",
      "       2.43508224e+02, 1.51264558e-07, 2.80149048e+02, 2.43113510e+02,\n",
      "       2.08632326e+00, 2.41898865e+02, 2.79083374e+02, 2.05243225e+02,\n",
      "       7.01479340e+01, 6.00644465e-11, 4.09826134e-05, 5.63611701e-12,\n",
      "       3.43657654e+02, 8.63066951e-09, 1.05098679e+02, 3.00244995e+02,\n",
      "       1.49046982e+02, 1.03752423e-11, 2.99917255e-02, 4.71799932e-09,\n",
      "       2.89229034e+02, 2.10985901e+02, 8.85145516e-12, 1.10838303e+02,\n",
      "       2.91010681e+02, 1.57320630e-02, 1.96937988e+02, 6.45666199e+01,\n",
      "       2.09265412e-03, 3.59845917e+02, 4.78594005e-01, 2.27801580e-11,\n",
      "       1.63517105e+02, 2.57626587e+02, 1.03720900e-07, 8.03120667e+02,\n",
      "       2.50731315e-12, 1.97413006e-11, 2.64785400e+02, 4.19028198e+02,\n",
      "       3.84462406e-10, 9.55862350e+01, 4.79601212e+01, 2.29374419e-11,\n",
      "       4.55584370e-07, 1.83405731e+02, 2.75949749e-12, 1.19257104e+00,\n",
      "       3.17874115e+02, 2.88768250e+02, 4.77775582e-04, 1.99426315e+02,\n",
      "       1.89737152e+02, 2.29855118e+02, 1.56735779e+02, 8.09541092e+01,\n",
      "       9.34733505e+01, 1.64416809e+02, 1.67413284e+02, 1.46967194e+02,\n",
      "       1.12777720e-09, 1.38136045e-06, 3.08552185e+02, 1.50601669e+02,\n",
      "       2.41034317e+02, 4.51430969e+02, 3.77892578e+02, 1.84673347e+01,\n",
      "       7.39952457e-12, 1.78159821e+02, 1.47240585e+02, 2.39540619e+02,\n",
      "       2.23146576e+02, 2.23635387e+00, 1.45735108e-11, 6.44820801e+02,\n",
      "       3.29984956e-10, 3.41970703e+02, 9.03417272e-11, 7.81610489e+01,\n",
      "       2.57082764e+02, 1.27553740e-12, 2.82385698e-10, 2.52997363e-11,\n",
      "       4.97367555e-12, 2.47030441e+02, 9.58105698e+01, 5.53726677e-05,\n",
      "       4.57591980e+02, 4.60236633e+02, 2.10190735e+02, 1.41346082e-12,\n",
      "       3.03707581e+02, 3.19171556e-12, 2.13809983e-08, 2.42233566e+02],\n",
      "      dtype=float32)]\n",
      "\n",
      "Layer: dropout_15\n",
      "Weights: []\n",
      "\n",
      "Layer: dense_7\n",
      "Weights: [array([[-1.70344822e-02,  8.97527635e-02, -1.14625834e-01, ...,\n",
      "        -1.19239546e-01,  5.61384559e-02, -9.40382630e-02],\n",
      "       [-3.47751379e-02,  2.81231273e-02, -4.42171581e-02, ...,\n",
      "        -6.64188489e-02, -1.38670683e-01, -1.37432605e-01],\n",
      "       [ 6.05097972e-02,  7.33722746e-02,  5.43980189e-02, ...,\n",
      "         6.02755025e-02, -8.40484351e-02,  7.32038682e-03],\n",
      "       ...,\n",
      "       [-5.56701012e-02,  9.34417695e-02, -1.11274764e-01, ...,\n",
      "        -8.04515854e-02, -2.83471532e-02, -7.88720772e-02],\n",
      "       [ 9.50498413e-03,  6.74515590e-02,  6.04775362e-02, ...,\n",
      "        -2.28688605e-02,  7.30108097e-02, -1.55262807e-02],\n",
      "       [-1.20513010e-04, -4.91922610e-02,  6.47682399e-02, ...,\n",
      "         6.03299867e-03, -3.58293131e-02, -3.50594521e-02]], dtype=float32), array([ 0.12556334, -0.18959662,  0.20505679, -0.00593806,  0.13174894,\n",
      "       -0.14358231,  0.09691011], dtype=float32)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"Weights: {layer.get_weights()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c133e589e287a29a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T22:55:31.486512Z",
     "start_time": "2024-12-02T22:55:29.995176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>179 172 174 177 181 178 178 173 181 203 197 180 167 156 150 150 146 143 144 145 96 57 53 64 78 128 125 125 125 126 119 131 185 213 213 219 223 228 230 226 226 225 220 213 207 201 193 184 184 175 163 152 158 167 172 175 184 189 190 180 167 153 148 147 143 141 144 135 81 61 52 62 75 123 117 115 116 111 141 199 215 215 217 218 220 199 211 197 187 186 195 193 173 171 162 172 156 143 140 113 105 127 124 119 135 150 162 164 174 149 143 144 141 141 142 125 89 93 92 93 94 117 107 102 99 137 205 214 215 221 221 219 220 196 203 209 196 183 167 182 180 173 153 142 135 108 121 72 61 91 97 129 140 136 135 146 165 186 156 137 139 137 140 104 78 100 114 123 137</th>\n",
       "      <th>Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46 46 46 44 45 46 48 50 51 49 52 55 56 61 64 6...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>140 135 159 183 191 198 194 192 188 187 188 19...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58 60 85 101 121 130 161 179 186 186 184 187 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>252 250 255 178 52 83 115 173 199 200 195 197 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38 36 32 31 43 71 92 107 129 137 117 100 88 96...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  179 172 174 177 181 178 178 173 181 203 197 180 167 156 150 150 146 143 144 145 96 57 53 64 78 128 125 125 125 126 119 131 185 213 213 219 223 228 230 226 226 225 220 213 207 201 193 184 184 175 163 152 158 167 172 175 184 189 190 180 167 153 148 147 143 141 144 135 81 61 52 62 75 123 117 115 116 111 141 199 215 215 217 218 220 199 211 197 187 186 195 193 173 171 162 172 156 143 140 113 105 127 124 119 135 150 162 164 174 149 143 144 141 141 142 125 89 93 92 93 94 117 107 102 99 137 205 214 215 221 221 219 220 196 203 209 196 183 167 182 180 173 153 142 135 108 121 72 61 91 97 129 140 136 135 146 165 186 156 137 139 137 140 104 78 100 114 123 137  \\\n",
       "2  46 46 46 44 45 46 48 50 51 49 52 55 56 61 64 6...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "5  140 135 159 183 191 198 194 192 188 187 188 19...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "3  58 60 85 101 121 130 161 179 186 186 184 187 1...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "5  252 250 255 178 52 83 115 173 199 200 195 197 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "6  38 36 32 31 43 71 92 107 129 137 117 100 88 96...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "   Training  \n",
       "2  Training  \n",
       "5  Training  \n",
       "3  Training  \n",
       "5  Training  \n",
       "6  Training  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"fer2013.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a84d2dfd9ff097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:04:42.179992Z",
     "start_time": "2024-12-02T23:04:40.645138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26510 entries, 2 to 2\n",
      "Data columns (total 2 columns):\n",
      " #   Column                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          --------------  ----- \n",
      " 0   179 172 174 177 181 178 178 173 181 203 197 180 167 156 150 150 146 143 144 145 96 57 53 64 78 128 125 125 125 126 119 131 185 213 213 219 223 228 230 226 226 225 220 213 207 201 193 184 184 175 163 152 158 167 172 175 184 189 190 180 167 153 148 147 143 141 144 135 81 61 52 62 75 123 117 115 116 111 141 199 215 215 217 218 220 199 211 197 187 186 195 193 173 171 162 172 156 143 140 113 105 127 124 119 135 150 162 164 174 149 143 144 141 141 142 125 89 93 92 93 94 117 107 102 99 137 205 214 215 221 221 219 220 196 203 209 196 183 167 182 180 173 153 142 135 108 121 72 61 91 97 129 140 136 135 146 165 186 156 137 139 137 140 104 78 100 114 123 137  26510 non-null  object\n",
      " 1   Training                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        26510 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 621.3+ KB\n",
      "None\n",
      "\n",
      "Column Names:\n",
      "['179 172 174 177 181 178 178 173 181 203 197 180 167 156 150 150 146 143 144 145 96 57 53 64 78 128 125 125 125 126 119 131 185 213 213 219 223 228 230 226 226 225 220 213 207 201 193 184 184 175 163 152 158 167 172 175 184 189 190 180 167 153 148 147 143 141 144 135 81 61 52 62 75 123 117 115 116 111 141 199 215 215 217 218 220 199 211 197 187 186 195 193 173 171 162 172 156 143 140 113 105 127 124 119 135 150 162 164 174 149 143 144 141 141 142 125 89 93 92 93 94 117 107 102 99 137 205 214 215 221 221 219 220 196 203 209 196 183 167 182 180 173 153 142 135 108 121 72 61 91 97 129 140 136 135 146 165 186 156 137 139 137 140 104 78 100 114 123 137', 'Training']\n",
      "\n",
      "First few rows:\n",
      "  179 172 174 177 181 178 178 173 181 203 197 180 167 156 150 150 146 143 144 145 96 57 53 64 78 128 125 125 125 126 119 131 185 213 213 219 223 228 230 226 226 225 220 213 207 201 193 184 184 175 163 152 158 167 172 175 184 189 190 180 167 153 148 147 143 141 144 135 81 61 52 62 75 123 117 115 116 111 141 199 215 215 217 218 220 199 211 197 187 186 195 193 173 171 162 172 156 143 140 113 105 127 124 119 135 150 162 164 174 149 143 144 141 141 142 125 89 93 92 93 94 117 107 102 99 137 205 214 215 221 221 219 220 196 203 209 196 183 167 182 180 173 153 142 135 108 121 72 61 91 97 129 140 136 135 146 165 186 156 137 139 137 140 104 78 100 114 123 137  \\\n",
      "2  46 46 46 44 45 46 48 50 51 49 52 55 56 61 64 6...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "5  140 135 159 183 191 198 194 192 188 187 188 19...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "3  58 60 85 101 121 130 161 179 186 186 184 187 1...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "5  252 250 255 178 52 83 115 173 199 200 195 197 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "6  38 36 32 31 43 71 92 107 129 137 117 100 88 96...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "\n",
      "   Training  \n",
      "2  Training  \n",
      "5  Training  \n",
      "3  Training  \n",
      "5  Training  \n",
      "6  Training  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset and inspect its structure\n",
    "df = pd.read_csv('fer2013.csv')\n",
    "print(\"DataFrame Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9323592eea7da582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:37:25.335673Z",
     "start_time": "2024-12-02T23:08:30.415052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully!\n",
      "Total samples: 26510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (26510, 48, 48, 1)\n",
      "Number of classes: 7\n",
      "Training samples: 19332\n",
      "Test samples: 3589\n",
      "\n",
      "Creating model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 48, 48, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 24, 24, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 24, 24, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 12, 12, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 12, 12, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               2359552   \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2733831 (10.43 MB)\n",
      "Trainable params: 2732423 (10.42 MB)\n",
      "Non-trainable params: 1408 (5.50 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training model...\n",
      "Epoch 1/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 2.2606 - accuracy: 0.2070\n",
      "Epoch 1: val_accuracy improved from -inf to 0.24519, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 112ms/step - loss: 2.2606 - accuracy: 0.2070 - val_loss: 1.9392 - val_accuracy: 0.2452 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "  1/302 [..............................] - ETA: 35s - loss: 2.2787 - accuracy: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sreeram/Desktop/skonDatabase/HON/Contracts/EmotionDetection/.venv/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - ETA: 0s - loss: 1.9194 - accuracy: 0.2315\n",
      "Epoch 2: val_accuracy improved from 0.24519 to 0.26609, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 36s 118ms/step - loss: 1.9194 - accuracy: 0.2315 - val_loss: 1.7937 - val_accuracy: 0.2661 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.7941 - accuracy: 0.2723\n",
      "Epoch 3: val_accuracy improved from 0.26609 to 0.27138, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 44s 145ms/step - loss: 1.7941 - accuracy: 0.2723 - val_loss: 1.7424 - val_accuracy: 0.2714 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.7295 - accuracy: 0.3062\n",
      "Epoch 4: val_accuracy improved from 0.27138 to 0.32349, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 33s 108ms/step - loss: 1.7295 - accuracy: 0.3062 - val_loss: 1.6667 - val_accuracy: 0.3235 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.6752 - accuracy: 0.3340\n",
      "Epoch 5: val_accuracy did not improve from 0.32349\n",
      "302/302 [==============================] - 33s 111ms/step - loss: 1.6752 - accuracy: 0.3340 - val_loss: 1.8577 - val_accuracy: 0.2870 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.6133 - accuracy: 0.3630\n",
      "Epoch 6: val_accuracy improved from 0.32349 to 0.42129, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 35s 115ms/step - loss: 1.6133 - accuracy: 0.3630 - val_loss: 1.5491 - val_accuracy: 0.4213 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.5587 - accuracy: 0.3883\n",
      "Epoch 7: val_accuracy did not improve from 0.42129\n",
      "302/302 [==============================] - 35s 116ms/step - loss: 1.5587 - accuracy: 0.3883 - val_loss: 1.6505 - val_accuracy: 0.4060 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.5155 - accuracy: 0.4072\n",
      "Epoch 8: val_accuracy improved from 0.42129 to 0.45333, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 113ms/step - loss: 1.5155 - accuracy: 0.4072 - val_loss: 1.4353 - val_accuracy: 0.4533 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.4903 - accuracy: 0.4215\n",
      "Epoch 9: val_accuracy did not improve from 0.45333\n",
      "302/302 [==============================] - 35s 114ms/step - loss: 1.4903 - accuracy: 0.4215 - val_loss: 1.5514 - val_accuracy: 0.4129 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.4540 - accuracy: 0.4378\n",
      "Epoch 10: val_accuracy improved from 0.45333 to 0.45612, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 35s 116ms/step - loss: 1.4540 - accuracy: 0.4378 - val_loss: 1.4319 - val_accuracy: 0.4561 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.4305 - accuracy: 0.4482\n",
      "Epoch 11: val_accuracy improved from 0.45612 to 0.48760, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 112ms/step - loss: 1.4305 - accuracy: 0.4482 - val_loss: 1.3154 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.4215 - accuracy: 0.4535\n",
      "Epoch 12: val_accuracy did not improve from 0.48760\n",
      "302/302 [==============================] - 37s 123ms/step - loss: 1.4215 - accuracy: 0.4535 - val_loss: 1.5708 - val_accuracy: 0.4018 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.4187 - accuracy: 0.4528\n",
      "Epoch 13: val_accuracy did not improve from 0.48760\n",
      "302/302 [==============================] - 34s 114ms/step - loss: 1.4187 - accuracy: 0.4528 - val_loss: 1.5572 - val_accuracy: 0.4455 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.3836 - accuracy: 0.4724\n",
      "Epoch 14: val_accuracy improved from 0.48760 to 0.53190, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 114ms/step - loss: 1.3836 - accuracy: 0.4724 - val_loss: 1.2145 - val_accuracy: 0.5319 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.4024 - accuracy: 0.4614\n",
      "Epoch 15: val_accuracy did not improve from 0.53190\n",
      "302/302 [==============================] - 35s 114ms/step - loss: 1.4024 - accuracy: 0.4614 - val_loss: 1.6215 - val_accuracy: 0.3536 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.3783 - accuracy: 0.4722\n",
      "Epoch 16: val_accuracy did not improve from 0.53190\n",
      "302/302 [==============================] - 35s 115ms/step - loss: 1.3783 - accuracy: 0.4722 - val_loss: 1.2409 - val_accuracy: 0.5132 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.3669 - accuracy: 0.4771\n",
      "Epoch 17: val_accuracy did not improve from 0.53190\n",
      "302/302 [==============================] - 35s 117ms/step - loss: 1.3669 - accuracy: 0.4771 - val_loss: 1.2486 - val_accuracy: 0.5258 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.3572 - accuracy: 0.4787\n",
      "Epoch 18: val_accuracy did not improve from 0.53190\n",
      "302/302 [==============================] - 35s 115ms/step - loss: 1.3572 - accuracy: 0.4787 - val_loss: 1.2428 - val_accuracy: 0.5171 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.3394 - accuracy: 0.4883\n",
      "Epoch 19: val_accuracy improved from 0.53190 to 0.53469, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 113ms/step - loss: 1.3394 - accuracy: 0.4883 - val_loss: 1.2100 - val_accuracy: 0.5347 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.3257 - accuracy: 0.4910\n",
      "Epoch 20: val_accuracy improved from 0.53469 to 0.53692, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 114ms/step - loss: 1.3257 - accuracy: 0.4910 - val_loss: 1.1967 - val_accuracy: 0.5369 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.3145 - accuracy: 0.5030\n",
      "Epoch 21: val_accuracy did not improve from 0.53692\n",
      "302/302 [==============================] - 34s 113ms/step - loss: 1.3145 - accuracy: 0.5030 - val_loss: 1.2247 - val_accuracy: 0.5280 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.3089 - accuracy: 0.4987\n",
      "Epoch 22: val_accuracy did not improve from 0.53692\n",
      "302/302 [==============================] - 34s 114ms/step - loss: 1.3089 - accuracy: 0.4987 - val_loss: 1.2063 - val_accuracy: 0.5313 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2994 - accuracy: 0.5026\n",
      "Epoch 23: val_accuracy improved from 0.53692 to 0.55726, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 35s 115ms/step - loss: 1.2994 - accuracy: 0.5026 - val_loss: 1.1762 - val_accuracy: 0.5573 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2986 - accuracy: 0.5025\n",
      "Epoch 24: val_accuracy did not improve from 0.55726\n",
      "302/302 [==============================] - 35s 115ms/step - loss: 1.2986 - accuracy: 0.5025 - val_loss: 1.2931 - val_accuracy: 0.5286 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.3062 - accuracy: 0.4989\n",
      "Epoch 25: val_accuracy did not improve from 0.55726\n",
      "302/302 [==============================] - 35s 116ms/step - loss: 1.3062 - accuracy: 0.4989 - val_loss: 1.2392 - val_accuracy: 0.5288 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2974 - accuracy: 0.5078\n",
      "Epoch 26: val_accuracy did not improve from 0.55726\n",
      "302/302 [==============================] - 35s 117ms/step - loss: 1.2974 - accuracy: 0.5078 - val_loss: 1.1914 - val_accuracy: 0.5525 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2892 - accuracy: 0.5097\n",
      "Epoch 27: val_accuracy improved from 0.55726 to 0.55949, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 35s 116ms/step - loss: 1.2892 - accuracy: 0.5097 - val_loss: 1.1342 - val_accuracy: 0.5595 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2930 - accuracy: 0.5096\n",
      "Epoch 28: val_accuracy improved from 0.55949 to 0.56283, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 113ms/step - loss: 1.2930 - accuracy: 0.5096 - val_loss: 1.1459 - val_accuracy: 0.5628 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2720 - accuracy: 0.5168\n",
      "Epoch 29: val_accuracy did not improve from 0.56283\n",
      "302/302 [==============================] - 34s 113ms/step - loss: 1.2720 - accuracy: 0.5168 - val_loss: 1.2363 - val_accuracy: 0.5344 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2736 - accuracy: 0.5172\n",
      "Epoch 30: val_accuracy did not improve from 0.56283\n",
      "302/302 [==============================] - 35s 115ms/step - loss: 1.2736 - accuracy: 0.5172 - val_loss: 1.1696 - val_accuracy: 0.5539 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2672 - accuracy: 0.5204\n",
      "Epoch 31: val_accuracy did not improve from 0.56283\n",
      "302/302 [==============================] - 35s 116ms/step - loss: 1.2672 - accuracy: 0.5204 - val_loss: 1.1320 - val_accuracy: 0.5628 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2739 - accuracy: 0.5175\n",
      "Epoch 32: val_accuracy improved from 0.56283 to 0.56812, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 113ms/step - loss: 1.2739 - accuracy: 0.5175 - val_loss: 1.1110 - val_accuracy: 0.5681 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2601 - accuracy: 0.5235\n",
      "Epoch 33: val_accuracy improved from 0.56812 to 0.57425, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 114ms/step - loss: 1.2601 - accuracy: 0.5235 - val_loss: 1.1303 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2598 - accuracy: 0.5194\n",
      "Epoch 34: val_accuracy did not improve from 0.57425\n",
      "302/302 [==============================] - 35s 115ms/step - loss: 1.2598 - accuracy: 0.5194 - val_loss: 1.1395 - val_accuracy: 0.5561 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2561 - accuracy: 0.5204\n",
      "Epoch 35: val_accuracy did not improve from 0.57425\n",
      "302/302 [==============================] - 34s 113ms/step - loss: 1.2561 - accuracy: 0.5204 - val_loss: 1.1622 - val_accuracy: 0.5695 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2385 - accuracy: 0.5302\n",
      "Epoch 36: val_accuracy improved from 0.57425 to 0.57955, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 114ms/step - loss: 1.2385 - accuracy: 0.5302 - val_loss: 1.1230 - val_accuracy: 0.5795 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2398 - accuracy: 0.5311\n",
      "Epoch 37: val_accuracy did not improve from 0.57955\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "302/302 [==============================] - 34s 114ms/step - loss: 1.2398 - accuracy: 0.5311 - val_loss: 1.3174 - val_accuracy: 0.5456 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2147 - accuracy: 0.5385\n",
      "Epoch 38: val_accuracy improved from 0.57955 to 0.59543, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 114ms/step - loss: 1.2147 - accuracy: 0.5385 - val_loss: 1.0696 - val_accuracy: 0.5954 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2061 - accuracy: 0.5393\n",
      "Epoch 39: val_accuracy improved from 0.59543 to 0.59794, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 36s 120ms/step - loss: 1.2061 - accuracy: 0.5393 - val_loss: 1.0611 - val_accuracy: 0.5979 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1971 - accuracy: 0.5487\n",
      "Epoch 40: val_accuracy improved from 0.59794 to 0.60490, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 32s 106ms/step - loss: 1.1971 - accuracy: 0.5487 - val_loss: 1.0670 - val_accuracy: 0.6049 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.2018 - accuracy: 0.5444\n",
      "Epoch 41: val_accuracy did not improve from 0.60490\n",
      "302/302 [==============================] - 32s 105ms/step - loss: 1.2018 - accuracy: 0.5444 - val_loss: 1.0632 - val_accuracy: 0.6007 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1931 - accuracy: 0.5465\n",
      "Epoch 42: val_accuracy did not improve from 0.60490\n",
      "302/302 [==============================] - 32s 106ms/step - loss: 1.1931 - accuracy: 0.5465 - val_loss: 1.1242 - val_accuracy: 0.5935 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1884 - accuracy: 0.5504\n",
      "Epoch 43: val_accuracy did not improve from 0.60490\n",
      "302/302 [==============================] - 32s 107ms/step - loss: 1.1884 - accuracy: 0.5504 - val_loss: 1.0685 - val_accuracy: 0.5988 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1902 - accuracy: 0.5484\n",
      "Epoch 44: val_accuracy improved from 0.60490 to 0.60797, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 33s 108ms/step - loss: 1.1902 - accuracy: 0.5484 - val_loss: 1.0456 - val_accuracy: 0.6080 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1782 - accuracy: 0.5552\n",
      "Epoch 45: val_accuracy did not improve from 0.60797\n",
      "302/302 [==============================] - 33s 108ms/step - loss: 1.1782 - accuracy: 0.5552 - val_loss: 1.0531 - val_accuracy: 0.6060 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1791 - accuracy: 0.5536\n",
      "Epoch 46: val_accuracy did not improve from 0.60797\n",
      "302/302 [==============================] - 33s 110ms/step - loss: 1.1791 - accuracy: 0.5536 - val_loss: 1.0769 - val_accuracy: 0.5977 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1733 - accuracy: 0.5553\n",
      "Epoch 47: val_accuracy improved from 0.60797 to 0.60908, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 34s 114ms/step - loss: 1.1733 - accuracy: 0.5553 - val_loss: 1.0479 - val_accuracy: 0.6091 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1812 - accuracy: 0.5531\n",
      "Epoch 48: val_accuracy did not improve from 0.60908\n",
      "302/302 [==============================] - 35s 114ms/step - loss: 1.1812 - accuracy: 0.5531 - val_loss: 1.1050 - val_accuracy: 0.6063 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1721 - accuracy: 0.5584\n",
      "Epoch 49: val_accuracy did not improve from 0.60908\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "302/302 [==============================] - 34s 113ms/step - loss: 1.1721 - accuracy: 0.5584 - val_loss: 1.0488 - val_accuracy: 0.6018 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "302/302 [==============================] - ETA: 0s - loss: 1.1722 - accuracy: 0.5550\n",
      "Epoch 50: val_accuracy improved from 0.60908 to 0.61131, saving model to checkpoints/best_model.h5\n",
      "302/302 [==============================] - 35s 115ms/step - loss: 1.1722 - accuracy: 0.5550 - val_loss: 1.0482 - val_accuracy: 0.6113 - lr: 1.0000e-05\n",
      "\n",
      "Training completed!\n",
      "Models saved in 'checkpoints/best_model.h5' and 'final_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "# import os\n",
    "# \n",
    "# def load_fer2013():\n",
    "#     \"\"\"Load and preprocess FER2013 dataset.\"\"\"\n",
    "#     try:\n",
    "#         # Read CSV with proper header names\n",
    "#         df = pd.read_csv('fer2013.csv', names=['emotion', 'pixels', 'Usage'], skiprows=1)\n",
    "#         print(\"Dataset loaded successfully!\")\n",
    "#         print(f\"Total samples: {len(df)}\")\n",
    "#         \n",
    "#         # Convert pixels string to array\n",
    "#         pixels = df['pixels'].str.split(' ').apply(lambda x: [int(pixel) for pixel in x])\n",
    "#         \n",
    "#         # Convert to numpy array and reshape\n",
    "#         X = np.array(pixels.tolist())\n",
    "#         X = X.reshape(-1, 48, 48, 1).astype('float32')\n",
    "#         \n",
    "#         # Normalize pixel values\n",
    "#         X = X / 255.0\n",
    "#         \n",
    "#         # Get labels\n",
    "#         y = df['emotion'].values\n",
    "#         \n",
    "#         print(f\"Input shape: {X.shape}\")\n",
    "#         print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "#         \n",
    "#         return X, y, df['Usage'].values\n",
    "#         \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading dataset: {str(e)}\")\n",
    "#         return None, None, None\n",
    "# \n",
    "# def create_model():\n",
    "#     \"\"\"Create CNN model for facial emotion recognition.\"\"\"\n",
    "#     model = Sequential([\n",
    "#         # First Convolution Block\n",
    "#         Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(48, 48, 1)),\n",
    "#         BatchNormalization(),\n",
    "#         MaxPooling2D(pool_size=(2, 2)),\n",
    "#         Dropout(0.25),\n",
    "#         \n",
    "#         # Second Convolution Block\n",
    "#         Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "#         BatchNormalization(),\n",
    "#         MaxPooling2D(pool_size=(2, 2)),\n",
    "#         Dropout(0.25),\n",
    "#         \n",
    "#         # Third Convolution Block\n",
    "#         Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "#         BatchNormalization(),\n",
    "#         MaxPooling2D(pool_size=(2, 2)),\n",
    "#         Dropout(0.25),\n",
    "#         \n",
    "#         # Dense Layers\n",
    "#         Flatten(),\n",
    "#         Dense(256, activation='relu'),\n",
    "#         BatchNormalization(),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(7, activation='softmax')\n",
    "#     ])\n",
    "#     \n",
    "#     return model\n",
    "# \n",
    "# def train_model():\n",
    "#     # Load and preprocess data\n",
    "#     print(\"Loading dataset...\")\n",
    "#     X, y, usage = load_fer2013()\n",
    "#     \n",
    "#     if X is None:\n",
    "#         return None, None\n",
    "#     \n",
    "#     # Split data based on Usage\n",
    "#     X_train = X[usage == 'Training']\n",
    "#     y_train = y[usage == 'Training']\n",
    "#     X_test = X[usage == 'PrivateTest']\n",
    "#     y_test = y[usage == 'PrivateTest']\n",
    "#     \n",
    "#     print(f\"Training samples: {len(X_train)}\")\n",
    "#     print(f\"Test samples: {len(X_test)}\")\n",
    "#     \n",
    "#     # Data augmentation\n",
    "#     datagen = ImageDataGenerator(\n",
    "#         rotation_range=20,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         zoom_range=0.2\n",
    "#     )\n",
    "#     \n",
    "#     # Create and compile model\n",
    "#     print(\"\\nCreating model...\")\n",
    "#     model = create_model()\n",
    "#     model.compile(\n",
    "#         optimizer=Adam(learning_rate=0.001),\n",
    "#         loss='sparse_categorical_crossentropy',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "#     \n",
    "#     # Print model summary\n",
    "#     model.summary()\n",
    "#     \n",
    "#     # Create checkpoint directory if it doesn't exist\n",
    "#     checkpoint_dir = 'checkpoints'\n",
    "#     if not os.path.exists(checkpoint_dir):\n",
    "#         os.makedirs(checkpoint_dir)\n",
    "#     \n",
    "#     # Callbacks with fixed ModelCheckpoint\n",
    "#     callbacks = [\n",
    "#         ModelCheckpoint(\n",
    "#             filepath=os.path.join(checkpoint_dir, 'best_model.h5'),  # Changed to .h5 format\n",
    "#             monitor='val_accuracy',\n",
    "#             mode='max',\n",
    "#             save_best_only=True,\n",
    "#             verbose=1\n",
    "#         ),\n",
    "#         EarlyStopping(\n",
    "#             monitor='val_loss',\n",
    "#             mode='min',\n",
    "#             patience=10,\n",
    "#             verbose=1\n",
    "#         ),\n",
    "#         ReduceLROnPlateau(\n",
    "#             monitor='val_loss',\n",
    "#             factor=0.1,\n",
    "#             patience=5,\n",
    "#             min_lr=1e-6,\n",
    "#             verbose=1\n",
    "#         )\n",
    "#     ]\n",
    "#     \n",
    "#     # Train the model\n",
    "#     print(\"\\nTraining model...\")\n",
    "#     history = model.fit(\n",
    "#         datagen.flow(X_train, y_train, batch_size=64),\n",
    "#         validation_data=(X_test, y_test),\n",
    "#         steps_per_epoch=len(X_train) // 64,\n",
    "#         epochs=50,\n",
    "#         callbacks=callbacks\n",
    "#     )\n",
    "#     \n",
    "#     return model, history\n",
    "# \n",
    "# if __name__ == \"__main__\":\n",
    "#     # Set memory growth for GPU\n",
    "#     physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#     if physical_devices:\n",
    "#         for device in physical_devices:\n",
    "#             tf.config.experimental.set_memory_growth(device, True)\n",
    "#     \n",
    "#     # Train the model\n",
    "#     model, history = train_model()\n",
    "#     \n",
    "#     if model is not None:\n",
    "#         # Save the final model\n",
    "#         model.save('final_model.h5')  # Changed to .h5 format\n",
    "#         print(\"\\nTraining completed!\")\n",
    "#         print(\"Models saved in 'checkpoints/best_model.h5' and 'final_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6997a8cba020b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T00:43:18.671431Z",
     "start_time": "2024-12-03T00:42:59.510206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Opening video file...\n",
      "Video properties:\n",
      "Resolution: 3024x1618\n",
      "FPS: 60\n",
      "Total frames: 198\n",
      "\n",
      "Processing video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 17:43:00.033 Python[34243:5335445] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 15.2% (Frame 30/198)\n",
      "Progress: 30.3% (Frame 60/198)\n",
      "Progress: 45.5% (Frame 90/198)\n",
      "Progress: 60.6% (Frame 120/198)\n",
      "Progress: 75.8% (Frame 150/198)\n",
      "Progress: 90.9% (Frame 180/198)\n",
      "\n",
      "Video processing completed!\n",
      "Processed video saved as: /Users/sreeram/Desktop/skonDatabase/HON/Contracts/EmotionDetection/output/emotion1_processed.mp4\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import load_model\n",
    "# \n",
    "# def process_video():\n",
    "#     # Video paths\n",
    "#     input_path = '/Users/sreeram/Desktop/skonDatabase/HON/Contracts/EmotionDetection/videos/emotion1.mp4'\n",
    "#     output_path = '/Users/sreeram/Desktop/skonDatabase/HON/Contracts/EmotionDetection/output/emotion1_processed.mp4'\n",
    "#     \n",
    "#     # Load the model\n",
    "#     print(\"Loading model...\")\n",
    "#     model = load_model('checkpoints/best_model.h5')\n",
    "#     \n",
    "#     # Load face cascade\n",
    "#     face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "#     \n",
    "#     # Emotion labels\n",
    "#     emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "#     \n",
    "#     # Open video file\n",
    "#     print(\"Opening video file...\")\n",
    "#     cap = cv2.VideoCapture(input_path)\n",
    "#     if not cap.isOpened():\n",
    "#         print(\"Error: Could not open video file\")\n",
    "#         return\n",
    "#     \n",
    "#     # Get video properties\n",
    "#     frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     \n",
    "#     print(f\"Video properties:\")\n",
    "#     print(f\"Resolution: {frame_width}x{frame_height}\")\n",
    "#     print(f\"FPS: {fps}\")\n",
    "#     print(f\"Total frames: {total_frames}\")\n",
    "#     \n",
    "#     # Create video writer\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "#     \n",
    "#     frame_count = 0\n",
    "#     print(\"\\nProcessing video...\")\n",
    "#     \n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#             \n",
    "#         frame_count += 1\n",
    "#         if frame_count % 30 == 0:  # Progress update every 30 frames\n",
    "#             progress = (frame_count / total_frames) * 100\n",
    "#             print(f\"Progress: {progress:.1f}% (Frame {frame_count}/{total_frames})\")\n",
    "#         \n",
    "#         # Convert to grayscale for face detection\n",
    "#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#         \n",
    "#         # Detect faces\n",
    "#         faces = face_cascade.detectMultiScale(\n",
    "#             gray,\n",
    "#             scaleFactor=1.1,\n",
    "#             minNeighbors=5,\n",
    "#             minSize=(30, 30)\n",
    "#         )\n",
    "#         \n",
    "#         # Process each face\n",
    "#         for (x, y, w, h) in faces:\n",
    "#             # Extract face ROI\n",
    "#             face_roi = gray[y:y+h, x:x+w]\n",
    "#             \n",
    "#             # Preprocess for model\n",
    "#             face_roi = cv2.resize(face_roi, (48, 48))\n",
    "#             face_roi = face_roi.astype('float32') / 255.0\n",
    "#             face_roi = np.expand_dims(face_roi, axis=[0, -1])\n",
    "#             \n",
    "#             # Predict emotion\n",
    "#             prediction = model.predict(face_roi, verbose=0)\n",
    "#             emotion_idx = np.argmax(prediction[0])\n",
    "#             emotion = emotions[emotion_idx]\n",
    "#             confidence = prediction[0][emotion_idx]\n",
    "#             \n",
    "#             # Draw rectangle around face\n",
    "#             cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "#             \n",
    "#             # Add emotion label with background\n",
    "#             label = f\"{emotion}: {confidence:.2f}\"\n",
    "#             label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "#             label_w, label_h = label_size\n",
    "#             \n",
    "#             # Draw label background\n",
    "#             cv2.rectangle(frame, \n",
    "#                         (x, y - label_h - 10), \n",
    "#                         (x + label_w + 10, y), \n",
    "#                         (0, 255, 0), \n",
    "#                         cv2.FILLED)\n",
    "#             \n",
    "#             # Draw label text\n",
    "#             cv2.putText(frame, label, (x + 5, y - 5), \n",
    "#                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "#         \n",
    "#         # Display the frame\n",
    "#         cv2.imshow('Emotion Detection', frame)\n",
    "#         \n",
    "#         # Write frame to output video\n",
    "#         out.write(frame)\n",
    "#         \n",
    "#         # Press 'q' to exit early\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     \n",
    "#     # Clean up\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     \n",
    "#     print(\"\\nVideo processing completed!\")\n",
    "#     print(f\"Processed video saved as: {output_path}\")\n",
    "# \n",
    "# if __name__ == \"__main__\":\n",
    "#     process_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9af2c39849c6971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T00:38:28.891111Z",
     "start_time": "2024-12-02T23:51:22.657590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully!\n",
      "Total samples: 26510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (26510, 48, 48, 1)\n",
      "Number of classes: 7\n",
      "\n",
      "Class distribution:\n",
      "Emotion 0: 3640 samples\n",
      "Emotion 1: 400 samples\n",
      "Emotion 2: 3763 samples\n",
      "Emotion 3: 6604 samples\n",
      "Emotion 4: 4515 samples\n",
      "Emotion 5: 2994 samples\n",
      "Emotion 6: 4594 samples\n",
      "Training samples: 19332\n",
      "Test samples: 3589\n",
      "\n",
      "Loading existing model for continued training...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 48, 48, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 24, 24, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 24, 24, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 12, 12, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 12, 12, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               2359552   \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2733831 (10.43 MB)\n",
      "Trainable params: 2732423 (10.42 MB)\n",
      "Non-trainable params: 1408 (5.50 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training model...\n",
      "Epoch 1/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2496 - accuracy: 0.5244\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58484, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 40s 65ms/step - loss: 1.2496 - accuracy: 0.5244 - val_loss: 1.1495 - val_accuracy: 0.5848 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "  2/604 [..............................] - ETA: 35s - loss: 1.0601 - accuracy: 0.5938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sreeram/Desktop/skonDatabase/HON/Contracts/EmotionDetection/.venv/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604/604 [==============================] - ETA: 0s - loss: 1.2512 - accuracy: 0.5288\n",
      "Epoch 2: val_accuracy did not improve from 0.58484\n",
      "604/604 [==============================] - 37s 62ms/step - loss: 1.2512 - accuracy: 0.5288 - val_loss: 1.1522 - val_accuracy: 0.5740 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2416 - accuracy: 0.5241\n",
      "Epoch 3: val_accuracy did not improve from 0.58484\n",
      "604/604 [==============================] - 37s 62ms/step - loss: 1.2416 - accuracy: 0.5241 - val_loss: 1.1153 - val_accuracy: 0.5782 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2362 - accuracy: 0.5304\n",
      "Epoch 4: val_accuracy did not improve from 0.58484\n",
      "604/604 [==============================] - 37s 61ms/step - loss: 1.2362 - accuracy: 0.5304 - val_loss: 1.1250 - val_accuracy: 0.5798 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2360 - accuracy: 0.5266\n",
      "Epoch 5: val_accuracy did not improve from 0.58484\n",
      "604/604 [==============================] - 38s 63ms/step - loss: 1.2360 - accuracy: 0.5266 - val_loss: 1.1355 - val_accuracy: 0.5709 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2378 - accuracy: 0.5346\n",
      "Epoch 6: val_accuracy did not improve from 0.58484\n",
      "604/604 [==============================] - 38s 64ms/step - loss: 1.2378 - accuracy: 0.5346 - val_loss: 1.1082 - val_accuracy: 0.5815 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2420 - accuracy: 0.5272\n",
      "Epoch 7: val_accuracy improved from 0.58484 to 0.59599, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 39s 65ms/step - loss: 1.2420 - accuracy: 0.5272 - val_loss: 1.0742 - val_accuracy: 0.5960 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2355 - accuracy: 0.5319\n",
      "Epoch 8: val_accuracy did not improve from 0.59599\n",
      "604/604 [==============================] - 40s 65ms/step - loss: 1.2355 - accuracy: 0.5319 - val_loss: 1.5981 - val_accuracy: 0.5598 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2298 - accuracy: 0.5373\n",
      "Epoch 9: val_accuracy did not improve from 0.59599\n",
      "604/604 [==============================] - 39s 65ms/step - loss: 1.2298 - accuracy: 0.5373 - val_loss: 1.0558 - val_accuracy: 0.5929 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2292 - accuracy: 0.5354\n",
      "Epoch 10: val_accuracy improved from 0.59599 to 0.60072, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 41s 67ms/step - loss: 1.2292 - accuracy: 0.5354 - val_loss: 1.0559 - val_accuracy: 0.6007 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2315 - accuracy: 0.5346\n",
      "Epoch 11: val_accuracy did not improve from 0.60072\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.2315 - accuracy: 0.5346 - val_loss: 1.2712 - val_accuracy: 0.5901 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2318 - accuracy: 0.5318\n",
      "Epoch 12: val_accuracy did not improve from 0.60072\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.2318 - accuracy: 0.5318 - val_loss: 1.1063 - val_accuracy: 0.5893 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2249 - accuracy: 0.5389\n",
      "Epoch 13: val_accuracy did not improve from 0.60072\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.2249 - accuracy: 0.5389 - val_loss: 1.1545 - val_accuracy: 0.5887 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2207 - accuracy: 0.5353\n",
      "Epoch 14: val_accuracy did not improve from 0.60072\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.2207 - accuracy: 0.5353 - val_loss: 1.8838 - val_accuracy: 0.5252 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2213 - accuracy: 0.5347\n",
      "Epoch 15: val_accuracy did not improve from 0.60072\n",
      "604/604 [==============================] - 39s 64ms/step - loss: 1.2213 - accuracy: 0.5347 - val_loss: 1.0687 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2226 - accuracy: 0.5346\n",
      "Epoch 16: val_accuracy improved from 0.60072 to 0.60518, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 39s 64ms/step - loss: 1.2226 - accuracy: 0.5346 - val_loss: 1.0477 - val_accuracy: 0.6052 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2124 - accuracy: 0.5369\n",
      "Epoch 17: val_accuracy did not improve from 0.60518\n",
      "604/604 [==============================] - 36s 59ms/step - loss: 1.2124 - accuracy: 0.5369 - val_loss: 1.0771 - val_accuracy: 0.5885 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2061 - accuracy: 0.5428\n",
      "Epoch 18: val_accuracy improved from 0.60518 to 0.60741, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 36s 59ms/step - loss: 1.2061 - accuracy: 0.5428 - val_loss: 1.0447 - val_accuracy: 0.6074 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2045 - accuracy: 0.5456\n",
      "Epoch 19: val_accuracy did not improve from 0.60741\n",
      "604/604 [==============================] - 37s 62ms/step - loss: 1.2045 - accuracy: 0.5456 - val_loss: 1.1082 - val_accuracy: 0.5879 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2060 - accuracy: 0.5414\n",
      "Epoch 20: val_accuracy did not improve from 0.60741\n",
      "604/604 [==============================] - 39s 64ms/step - loss: 1.2060 - accuracy: 0.5414 - val_loss: 1.0617 - val_accuracy: 0.6016 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2015 - accuracy: 0.5459\n",
      "Epoch 21: val_accuracy did not improve from 0.60741\n",
      "604/604 [==============================] - 39s 65ms/step - loss: 1.2015 - accuracy: 0.5459 - val_loss: 1.0500 - val_accuracy: 0.6041 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2054 - accuracy: 0.5459\n",
      "Epoch 22: val_accuracy did not improve from 0.60741\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.2054 - accuracy: 0.5459 - val_loss: 1.1060 - val_accuracy: 0.5899 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2381 - accuracy: 0.5310\n",
      "Epoch 23: val_accuracy did not improve from 0.60741\n",
      "604/604 [==============================] - 41s 67ms/step - loss: 1.2381 - accuracy: 0.5310 - val_loss: 1.2562 - val_accuracy: 0.5954 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2102 - accuracy: 0.5431\n",
      "Epoch 24: val_accuracy did not improve from 0.60741\n",
      "604/604 [==============================] - 41s 68ms/step - loss: 1.2102 - accuracy: 0.5431 - val_loss: 1.0558 - val_accuracy: 0.5982 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1919 - accuracy: 0.5495\n",
      "Epoch 25: val_accuracy did not improve from 0.60741\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1919 - accuracy: 0.5495 - val_loss: 1.2913 - val_accuracy: 0.5915 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2121 - accuracy: 0.5406\n",
      "Epoch 26: val_accuracy did not improve from 0.60741\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "604/604 [==============================] - 40s 65ms/step - loss: 1.2121 - accuracy: 0.5406 - val_loss: 1.0727 - val_accuracy: 0.5879 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1857 - accuracy: 0.5516\n",
      "Epoch 27: val_accuracy improved from 0.60741 to 0.61410, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1857 - accuracy: 0.5516 - val_loss: 1.0332 - val_accuracy: 0.6141 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1885 - accuracy: 0.5483\n",
      "Epoch 28: val_accuracy did not improve from 0.61410\n",
      "604/604 [==============================] - 38s 64ms/step - loss: 1.1885 - accuracy: 0.5483 - val_loss: 1.0211 - val_accuracy: 0.6135 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.5568\n",
      "Epoch 29: val_accuracy improved from 0.61410 to 0.61493, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 39s 65ms/step - loss: 1.1712 - accuracy: 0.5568 - val_loss: 1.0148 - val_accuracy: 0.6149 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1757 - accuracy: 0.5542\n",
      "Epoch 30: val_accuracy improved from 0.61493 to 0.61633, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 38s 63ms/step - loss: 1.1757 - accuracy: 0.5542 - val_loss: 1.0085 - val_accuracy: 0.6163 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1693 - accuracy: 0.5547\n",
      "Epoch 31: val_accuracy did not improve from 0.61633\n",
      "604/604 [==============================] - 38s 64ms/step - loss: 1.1693 - accuracy: 0.5547 - val_loss: 1.0239 - val_accuracy: 0.6141 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1718 - accuracy: 0.5554\n",
      "Epoch 32: val_accuracy improved from 0.61633 to 0.62079, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 40s 67ms/step - loss: 1.1718 - accuracy: 0.5554 - val_loss: 1.0148 - val_accuracy: 0.6208 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1645 - accuracy: 0.5628\n",
      "Epoch 33: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 40s 67ms/step - loss: 1.1645 - accuracy: 0.5628 - val_loss: 1.0157 - val_accuracy: 0.6194 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1640 - accuracy: 0.5573\n",
      "Epoch 34: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1640 - accuracy: 0.5573 - val_loss: 1.0221 - val_accuracy: 0.6135 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1660 - accuracy: 0.5593\n",
      "Epoch 35: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1660 - accuracy: 0.5593 - val_loss: 1.0080 - val_accuracy: 0.6172 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1678 - accuracy: 0.5589\n",
      "Epoch 36: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 41s 67ms/step - loss: 1.1678 - accuracy: 0.5589 - val_loss: 1.0086 - val_accuracy: 0.6166 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1586 - accuracy: 0.5661\n",
      "Epoch 37: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 41s 67ms/step - loss: 1.1586 - accuracy: 0.5661 - val_loss: 1.0306 - val_accuracy: 0.6155 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1611 - accuracy: 0.5620\n",
      "Epoch 38: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 39s 65ms/step - loss: 1.1611 - accuracy: 0.5620 - val_loss: 1.0110 - val_accuracy: 0.6194 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1509 - accuracy: 0.5668\n",
      "Epoch 39: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1509 - accuracy: 0.5668 - val_loss: 1.0234 - val_accuracy: 0.6205 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1525 - accuracy: 0.5666\n",
      "Epoch 40: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1525 - accuracy: 0.5666 - val_loss: 1.0074 - val_accuracy: 0.6166 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1568 - accuracy: 0.5674\n",
      "Epoch 41: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 40s 67ms/step - loss: 1.1568 - accuracy: 0.5674 - val_loss: 1.0143 - val_accuracy: 0.6205 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1548 - accuracy: 0.5643\n",
      "Epoch 42: val_accuracy did not improve from 0.62079\n",
      "604/604 [==============================] - 38s 64ms/step - loss: 1.1548 - accuracy: 0.5643 - val_loss: 1.0335 - val_accuracy: 0.6202 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1521 - accuracy: 0.5667\n",
      "Epoch 43: val_accuracy improved from 0.62079 to 0.62719, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 38s 63ms/step - loss: 1.1521 - accuracy: 0.5667 - val_loss: 1.0210 - val_accuracy: 0.6272 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1527 - accuracy: 0.5648\n",
      "Epoch 44: val_accuracy did not improve from 0.62719\n",
      "604/604 [==============================] - 38s 63ms/step - loss: 1.1527 - accuracy: 0.5648 - val_loss: 1.0044 - val_accuracy: 0.6194 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1560 - accuracy: 0.5652\n",
      "Epoch 45: val_accuracy did not improve from 0.62719\n",
      "604/604 [==============================] - 39s 64ms/step - loss: 1.1560 - accuracy: 0.5652 - val_loss: 1.0405 - val_accuracy: 0.6160 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1422 - accuracy: 0.5655\n",
      "Epoch 46: val_accuracy did not improve from 0.62719\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1422 - accuracy: 0.5655 - val_loss: 1.0357 - val_accuracy: 0.6239 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1480 - accuracy: 0.5690\n",
      "Epoch 47: val_accuracy did not improve from 0.62719\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1480 - accuracy: 0.5690 - val_loss: 1.0111 - val_accuracy: 0.6258 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1413 - accuracy: 0.5678\n",
      "Epoch 48: val_accuracy did not improve from 0.62719\n",
      "604/604 [==============================] - 40s 67ms/step - loss: 1.1413 - accuracy: 0.5678 - val_loss: 1.0485 - val_accuracy: 0.6127 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1434 - accuracy: 0.5681\n",
      "Epoch 49: val_accuracy did not improve from 0.62719\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1434 - accuracy: 0.5681 - val_loss: 1.0039 - val_accuracy: 0.6233 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1453 - accuracy: 0.5666\n",
      "Epoch 50: val_accuracy improved from 0.62719 to 0.62803, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 40s 67ms/step - loss: 1.1453 - accuracy: 0.5666 - val_loss: 1.0070 - val_accuracy: 0.6280 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1472 - accuracy: 0.5648\n",
      "Epoch 51: val_accuracy did not improve from 0.62803\n",
      "604/604 [==============================] - 41s 67ms/step - loss: 1.1472 - accuracy: 0.5648 - val_loss: 1.0696 - val_accuracy: 0.6144 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1376 - accuracy: 0.5680\n",
      "Epoch 52: val_accuracy did not improve from 0.62803\n",
      "604/604 [==============================] - 41s 68ms/step - loss: 1.1376 - accuracy: 0.5680 - val_loss: 1.0020 - val_accuracy: 0.6258 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1429 - accuracy: 0.5663\n",
      "Epoch 53: val_accuracy improved from 0.62803 to 0.62887, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 41s 67ms/step - loss: 1.1429 - accuracy: 0.5663 - val_loss: 1.0086 - val_accuracy: 0.6289 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1359 - accuracy: 0.5751\n",
      "Epoch 54: val_accuracy did not improve from 0.62887\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1359 - accuracy: 0.5751 - val_loss: 1.0253 - val_accuracy: 0.6213 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1367 - accuracy: 0.5706\n",
      "Epoch 55: val_accuracy improved from 0.62887 to 0.63221, saving model to checkpoints/best_model.h5\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1367 - accuracy: 0.5706 - val_loss: 1.0072 - val_accuracy: 0.6322 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1340 - accuracy: 0.5710\n",
      "Epoch 56: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 41s 68ms/step - loss: 1.1340 - accuracy: 0.5710 - val_loss: 0.9904 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1350 - accuracy: 0.5669\n",
      "Epoch 57: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 42s 70ms/step - loss: 1.1350 - accuracy: 0.5669 - val_loss: 1.0083 - val_accuracy: 0.6266 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1363 - accuracy: 0.5737\n",
      "Epoch 58: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 42s 69ms/step - loss: 1.1363 - accuracy: 0.5737 - val_loss: 1.0002 - val_accuracy: 0.6278 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1337 - accuracy: 0.5676\n",
      "Epoch 59: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 40s 65ms/step - loss: 1.1337 - accuracy: 0.5676 - val_loss: 1.0234 - val_accuracy: 0.6213 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1381 - accuracy: 0.5709\n",
      "Epoch 60: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1381 - accuracy: 0.5709 - val_loss: 1.0084 - val_accuracy: 0.6244 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1337 - accuracy: 0.5720\n",
      "Epoch 61: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 41s 67ms/step - loss: 1.1337 - accuracy: 0.5720 - val_loss: 1.0180 - val_accuracy: 0.6211 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1340 - accuracy: 0.5688\n",
      "Epoch 62: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 42s 69ms/step - loss: 1.1340 - accuracy: 0.5688 - val_loss: 1.0417 - val_accuracy: 0.6239 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1424 - accuracy: 0.5680\n",
      "Epoch 63: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1424 - accuracy: 0.5680 - val_loss: 1.0060 - val_accuracy: 0.6247 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1376 - accuracy: 0.5721\n",
      "Epoch 64: val_accuracy did not improve from 0.63221\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "604/604 [==============================] - 40s 66ms/step - loss: 1.1376 - accuracy: 0.5721 - val_loss: 1.0047 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1364 - accuracy: 0.5729\n",
      "Epoch 65: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 39s 64ms/step - loss: 1.1364 - accuracy: 0.5729 - val_loss: 0.9947 - val_accuracy: 0.6266 - lr: 2.0000e-05\n",
      "Epoch 66/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1302 - accuracy: 0.5746\n",
      "Epoch 66: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 39s 64ms/step - loss: 1.1302 - accuracy: 0.5746 - val_loss: 0.9908 - val_accuracy: 0.6266 - lr: 2.0000e-05\n",
      "Epoch 67/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1275 - accuracy: 0.5763\n",
      "Epoch 67: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 40s 67ms/step - loss: 1.1275 - accuracy: 0.5763 - val_loss: 0.9943 - val_accuracy: 0.6244 - lr: 2.0000e-05\n",
      "Epoch 68/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1305 - accuracy: 0.5733\n",
      "Epoch 68: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 42s 69ms/step - loss: 1.1305 - accuracy: 0.5733 - val_loss: 0.9963 - val_accuracy: 0.6255 - lr: 2.0000e-05\n",
      "Epoch 69/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1339 - accuracy: 0.5711\n",
      "Epoch 69: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 42s 69ms/step - loss: 1.1339 - accuracy: 0.5711 - val_loss: 1.0021 - val_accuracy: 0.6272 - lr: 2.0000e-05\n",
      "Epoch 70/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1313 - accuracy: 0.5784\n",
      "Epoch 70: val_accuracy did not improve from 0.63221\n",
      "604/604 [==============================] - 39s 65ms/step - loss: 1.1313 - accuracy: 0.5784 - val_loss: 0.9969 - val_accuracy: 0.6286 - lr: 2.0000e-05\n",
      "Epoch 71/100\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1243 - accuracy: 0.5777\n",
      "Epoch 71: val_accuracy did not improve from 0.63221\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "604/604 [==============================] - 39s 65ms/step - loss: 1.1243 - accuracy: 0.5777 - val_loss: 1.0007 - val_accuracy: 0.6272 - lr: 2.0000e-05\n",
      "Epoch 71: early stopping\n",
      "\n",
      "Training completed!\n",
      "Models saved in 'checkpoints/best_model.h5' and 'final_model.h5'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "def load_fer2013():\n",
    "    \"\"\"Load and preprocess FER2013 dataset.\"\"\"\n",
    "    try:\n",
    "        # Read CSV with proper header names\n",
    "        df = pd.read_csv('fer2013.csv', names=['emotion', 'pixels', 'Usage'], skiprows=1)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "        print(f\"Total samples: {len(df)}\")\n",
    "        \n",
    "        # Convert pixels string to array\n",
    "        pixels = df['pixels'].str.split(' ').apply(lambda x: [int(pixel) for pixel in x])\n",
    "        \n",
    "        # Convert to numpy array and reshape\n",
    "        X = np.array(pixels.tolist())\n",
    "        X = X.reshape(-1, 48, 48, 1).astype('float32')\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        X = X / 255.0\n",
    "        \n",
    "        # Get labels\n",
    "        y = df['emotion'].values\n",
    "        \n",
    "        print(f\"Input shape: {X.shape}\")\n",
    "        print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "        print(\"\\nClass distribution:\")\n",
    "        for emotion_id, count in enumerate(np.bincount(y)):\n",
    "            print(f\"Emotion {emotion_id}: {count} samples\")\n",
    "        \n",
    "        return X, y, df['Usage'].values\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def create_improved_model():\n",
    "    \"\"\"Create an improved CNN model for facial emotion recognition.\"\"\"\n",
    "    model = Sequential([\n",
    "        # First Convolution Block - Increased filters\n",
    "        Conv2D(96, (3, 3), padding='same', activation='relu', input_shape=(48, 48, 1)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(96, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second Convolution Block - Deeper\n",
    "        Conv2D(192, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(192, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third Convolution Block\n",
    "        Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Dense Layers - Wider\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(7, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(continue_training=False):\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading dataset...\")\n",
    "    X, y, usage = load_fer2013()\n",
    "    \n",
    "    if X is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Split data based on Usage\n",
    "    X_train = X[usage == 'Training']\n",
    "    y_train = y[usage == 'Training']\n",
    "    X_test = X[usage == 'PrivateTest']\n",
    "    y_test = y[usage == 'PrivateTest']\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train)}\")\n",
    "    print(f\"Test samples: {len(X_test)}\")\n",
    "    \n",
    "    # Enhanced data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    if continue_training and os.path.exists('checkpoints/best_model.h5'):\n",
    "        print(\"\\nLoading existing model for continued training...\")\n",
    "        model = load_model('checkpoints/best_model.h5')\n",
    "    else:\n",
    "        print(\"\\nCreating new model...\")\n",
    "        model = create_improved_model()\n",
    "    \n",
    "    # Compile model with reduced learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Print model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    checkpoint_dir = 'checkpoints'\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    # Callbacks with improved parameters\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            filepath=os.path.join(checkpoint_dir, 'best_model.h5'),\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=15,  # Increased patience\n",
    "            verbose=1,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,  # More gentle reduction\n",
    "            patience=8,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"\\nTraining model...\")\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=32),  # Reduced batch size\n",
    "        validation_data=(X_test, y_test),\n",
    "        steps_per_epoch=len(X_train) // 32,\n",
    "        epochs=100,  # Increased epochs\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set memory growth for GPU\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if physical_devices:\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "    \n",
    "    # Train the model with continued training option\n",
    "    continue_training = True  # Set to True to continue training from previous model\n",
    "    model, history = train_model(continue_training)\n",
    "    \n",
    "    if model is not None:\n",
    "        # Save the final model\n",
    "        model.save('final_model.h5')\n",
    "        print(\"\\nTraining completed!\")\n",
    "        print(\"Models saved in 'checkpoints/best_model.h5' and 'final_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54518509a2010d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T00:46:20.804840Z",
     "start_time": "2024-12-03T00:45:51.272990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Opening video file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 17:46:01.643 Python[34655:5374043] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed video saved as: ./output/emotion1_processed.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def process_video():\n",
    "    # Video paths\n",
    "    input_path = './videos/emotion1.mp4'\n",
    "    output_path = './output/emotion1_processed.mp4'\n",
    "    \n",
    "    # Load the model\n",
    "    print(\"Loading model...\")\n",
    "    model = load_model('checkpoints/best_model.h5')\n",
    "    \n",
    "    # Load face cascade\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Emotion labels\n",
    "    emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    \n",
    "    # Open video file\n",
    "    print(\"Opening video file...\")\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Convert to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces with adjusted parameters\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=4,  # Reduced to detect more faces\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        \n",
    "        # Process each face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract and preprocess face\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            face_roi = cv2.resize(face_roi, (48, 48))\n",
    "            face_roi = face_roi.astype('float32') / 255.0\n",
    "            face_roi = np.expand_dims(face_roi, axis=[0, -1])\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = model.predict(face_roi, verbose=0)[0]\n",
    "            \n",
    "            # Get top 2 emotions and their probabilities\n",
    "            top_2_idx = np.argsort(predictions)[-2:][::-1]\n",
    "            emotion_1 = emotions[top_2_idx[0]]\n",
    "            emotion_2 = emotions[top_2_idx[1]]\n",
    "            conf_1 = predictions[top_2_idx[0]]\n",
    "            conf_2 = predictions[top_2_idx[1]]\n",
    "            \n",
    "            # Bias towards surprise if it's the second highest prediction\n",
    "            surprise_idx = emotions.index('Surprise')\n",
    "            if top_2_idx[1] == surprise_idx and conf_2 > 0.2:  # Lowered threshold for surprise\n",
    "                emotion_1 = 'Surprise'\n",
    "                conf_1 = conf_2\n",
    "            \n",
    "            # Draw rectangle around face\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Add emotion labels with background\n",
    "            label_1 = f\"{emotion_1}: {conf_1:.2f}\"\n",
    "            label_2 = f\"{emotion_2}: {conf_2:.2f}\"\n",
    "            \n",
    "            # Draw first emotion\n",
    "            label_size, _ = cv2.getTextSize(label_1, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "            cv2.rectangle(frame, \n",
    "                        (x, y - label_size[1] - 10), \n",
    "                        (x + label_size[0], y), \n",
    "                        (0, 255, 0), \n",
    "                        cv2.FILLED)\n",
    "            cv2.putText(frame, label_1, (x, y - 5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "            \n",
    "            # Draw second emotion below\n",
    "            label_size, _ = cv2.getTextSize(label_2, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "            cv2.rectangle(frame, \n",
    "                        (x, y - label_size[1] - 30), \n",
    "                        (x + label_size[0], y - 20), \n",
    "                        (255, 255, 0), \n",
    "                        cv2.FILLED)\n",
    "            cv2.putText(frame, label_2, (x, y - 25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow('Emotion Detection', frame)\n",
    "        out.write(frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\nProcessed video saved as: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6dac2f9010c7ec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-03T00:47:52.322651Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "def start_webcam_detection():\n",
    "    # Load the model\n",
    "    print(\"Loading model...\")\n",
    "    model = load_model('best_model.h5')\n",
    "    \n",
    "    # Load face cascade\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Emotion labels\n",
    "    emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    \n",
    "    # Start webcam\n",
    "    print(\"Starting webcam...\")\n",
    "    cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
    "    \n",
    "    # Set webcam properties for better quality\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    # FPS calculation variables\n",
    "    fps_start_time = time.time()\n",
    "    fps = 0\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Can't receive frame from webcam\")\n",
    "            break\n",
    "            \n",
    "        # Calculate FPS\n",
    "        frame_count += 1\n",
    "        if frame_count >= 30:\n",
    "            fps = frame_count / (time.time() - fps_start_time)\n",
    "            fps_start_time = time.time()\n",
    "            frame_count = 0\n",
    "        \n",
    "        # Convert to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=4,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        \n",
    "        # Process each face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract and preprocess face\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            face_roi = cv2.resize(face_roi, (48, 48))\n",
    "            face_roi = face_roi.astype('float32') / 255.0\n",
    "            face_roi = np.expand_dims(face_roi, axis=[0, -1])\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = model.predict(face_roi, verbose=0)[0]\n",
    "            \n",
    "            # Get top 2 emotions and their probabilities\n",
    "            top_2_idx = np.argsort(predictions)[-2:][::-1]\n",
    "            emotion_1 = emotions[top_2_idx[0]]\n",
    "            emotion_2 = emotions[top_2_idx[1]]\n",
    "            conf_1 = predictions[top_2_idx[0]]\n",
    "            conf_2 = predictions[top_2_idx[1]]\n",
    "            \n",
    "            # Bias towards surprise if it's close\n",
    "            surprise_idx = emotions.index('Surprise')\n",
    "            if top_2_idx[1] == surprise_idx and conf_2 > 0.2:\n",
    "                emotion_1 = 'Surprise'\n",
    "                conf_1 = conf_2\n",
    "            \n",
    "            # Draw rectangle around face\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Add emotion labels with background\n",
    "            label_1 = f\"{emotion_1}: {conf_1:.2f}\"\n",
    "            label_2 = f\"{emotion_2}: {conf_2:.2f}\"\n",
    "            \n",
    "            # Draw first emotion\n",
    "            label_size, _ = cv2.getTextSize(label_1, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "            cv2.rectangle(frame, \n",
    "                        (x, y - label_size[1] - 10), \n",
    "                        (x + label_size[0], y), \n",
    "                        (0, 255, 0), \n",
    "                        cv2.FILLED)\n",
    "            cv2.putText(frame, label_1, (x, y - 5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "            \n",
    "            # Draw second emotion below\n",
    "            label_size, _ = cv2.getTextSize(label_2, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "            cv2.rectangle(frame, \n",
    "                        (x, y - label_size[1] - 30), \n",
    "                        (x + label_size[0], y - 20), \n",
    "                        (255, 255, 0), \n",
    "                        cv2.FILLED)\n",
    "            cv2.putText(frame, label_2, (x, y - 25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
    "        \n",
    "        # Add FPS counter\n",
    "        cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Show frame\n",
    "        cv2.imshow('Emotion Detection (Press Q to quit)', frame)\n",
    "        \n",
    "        # Break loop on 'q' press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Clean up\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Webcam closed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_webcam_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emodet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
